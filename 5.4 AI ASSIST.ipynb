{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLuMFLIP7dJBxSMFIkH9CD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagadeesh01032005/AI-ASSIST-CODING/blob/main/5.4%20AI%20ASSIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1"
      ],
      "metadata": {
        "id": "v3b2dPqm6v22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = input(\"Enter your name: \")\n",
        "age = input(\"Enter your age: \")\n",
        "email = input(\"Enter your email: \")\n",
        "\n",
        "user_data = {\n",
        "    \"name\": name,\n",
        "    \"age\": age,\n",
        "    \"email\": email\n",
        "}\n",
        "\n",
        "print(\"\\nCollected User Data:\")\n",
        "print(user_data)\n",
        "\n",
        "# -----------------------------\n",
        "# Data Protection & Anonymization Notes:\n",
        "# - Personal data should not be stored in plain text. Instead, consider storing only necessary anonymized or pseudonymized data.\n",
        "# - Email can be anonymized using hashing (e.g., SHA-256) to create a one-way, irreversible representation. This prevents direct identification.\n",
        "# - Sensitive data (like certain personal identifiers) should be encrypted before storage using strong encryption algorithms (e.g., AES-256).\n",
        "#   Encryption ensures that even if data is accessed, it remains unreadable without the decryption key.\n",
        "# - Access to the data should be restricted using proper role-based access control (RBAC) and permissions, ensuring only authorized personnel can view it.\n",
        "# - Avoid sharing personal data in logs, temporary files, or public repositories.\n",
        "# - Implement data retention policies to delete data that is no longer needed.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "M9DKEN863cwo",
        "outputId": "b606ef1e-2db2-4543-f1cf-1dfcc4577270"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your name: Jagadeesh\n",
            "Enter your age: 20\n",
            "Enter your email: jagadeeshmollguri@gmail.com\n",
            "\n",
            "Collected User Data:\n",
            "{'name': 'Jagadeesh', 'age': 20, 'email': 'jagadeeshmollguri@gmail.com'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b9ed7d67",
        "outputId": "1e46ee93-27f1-4f8b-ce2c-d236c68dcf86"
      },
      "source": [
        "!pip install cryptography"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography) (2.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "463e3cea",
        "outputId": "b537ac75-3207-412c-cce8-fffa5c9cab28"
      },
      "source": [
        "from cryptography.fernet import Fernet\n",
        "\n",
        "# 1. Generate a key (THIS SHOULD BE STORED SECURELY, NOT HARDCODED OR PRINTED IN PRODUCTION)\n",
        "# For demonstration purposes, we'll generate and print it here.\n",
        "key = Fernet.generate_key()\n",
        "f = Fernet(key)\n",
        "\n",
        "print(f\"Generated Encryption Key (KEEP THIS SECRET!): {key.decode()}\")\n",
        "\n",
        "# 2. Encrypt the data (e.g., the collected name)\n",
        "# Data must be bytes, so we encode it.\n",
        "data_to_encrypt = user_data['name'].encode()\n",
        "encrypted_data = f.encrypt(data_to_encrypt)\n",
        "\n",
        "print(f\"\\nOriginal data (name): {user_data['name']}\")\n",
        "print(f\"Encrypted data: {encrypted_data}\")\n",
        "\n",
        "# 3. Decrypt the data (only possible with the correct key)\n",
        "decrypted_data = f.decrypt(encrypted_data).decode()\n",
        "\n",
        "print(f\"Decrypted data: {decrypted_data}\")\n",
        "\n",
        "# Important considerations for production:\n",
        "# - Store the encryption key securely (e.g., in a Hardware Security Module (HSM), secure key management service, or environment variables), never hardcode it.\n",
        "# - Manage keys carefully: key rotation, secure distribution, and access control.\n",
        "# - Use appropriate encryption for data at rest (stored) and data in transit (over networks).\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Encryption Key (KEEP THIS SECRET!): IkazZYJk7vCRhmU2OfuEH2CV3CF6dV4tP5Rd2gvBVXQ=\n",
            "\n",
            "Original data (name): Jagadeesh\n",
            "Encrypted data: b'gAAAAABpexvjVoQJJJFj2HGuRCF7_ntsz4EmA9YQQUkZHjLQ96cWRbJtnuWCfwI5qit63OZrf1f-xrVcqHbHDnpbBNSuvwygfQ=='\n",
            "Decrypted data: Jagadeesh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d85e9220",
        "outputId": "4241cf05-34c3-4728-fcb3-560a24688f54"
      },
      "source": [
        "import hashlib\n",
        "\n",
        "# Encode the email to bytes before hashing\n",
        "hashed_email = hashlib.sha256(email.encode()).hexdigest()\n",
        "\n",
        "print(\"\\nAnonymized Email (Hashed using SHA-256):\")\n",
        "print(hashed_email)\n",
        "\n",
        "# Note: Hashing is a one-way function. This means the original email cannot be recovered from the hash.\n",
        "# This is suitable for anonymization where direct identification is not desired, but data integrity can be verified."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Anonymized Email (Hashed using SHA-256):\n",
            "7081fe3da591e63a53756b46d65b0ea4048b4e23ce5745f228587afe37282310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUMMARY**\n",
        "User Data Collection: A Python script was generated to collect basic user information (name, age, email) via input prompts.\n",
        "Data Protection Notes: Comments were added to the code outlining methods for data anonymization and protection, such as hashing emails and encrypting sensitive data.\n",
        "Security Best Practices: The notes emphasized secure key storage, access control, and data retention policies for responsible data handling."
      ],
      "metadata": {
        "id": "bsaoB9CqArUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2\n"
      ],
      "metadata": {
        "id": "SrgmDT4k69Tv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7a9a0ddd",
        "outputId": "fcc70e95-4cbc-4b67-846d-8d83917ab745"
      },
      "source": [
        "import nltk\n",
        "\n",
        "!pip install textblob\n",
        "\n",
        "# Download the necessary NLTK corpora for TextBlob\n",
        "# This might take a moment the first time it's run\n",
        "try:\n",
        "    nltk.data.find('corpora/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('corpora/averaged_perceptron_tagger')\n",
        "except LookupError:\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "try:\n",
        "    nltk.data.find('corpora/brown')\n",
        "except LookupError:\n",
        "    nltk.download('brown')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ad7ee850",
        "outputId": "b0561bc6-df79-4997-e34d-8f67ef6d1f7f"
      },
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Performs sentiment analysis on the given text input.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to analyze.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the polarity score (float) and the sentiment classification (str).\n",
        "               Sentiment is classified as 'positive', 'negative', or 'neutral'.\n",
        "    \"\"\"\n",
        "    analysis = TextBlob(text)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "\n",
        "    if polarity > 0:\n",
        "        sentiment_class = 'positive'\n",
        "    elif polarity < 0:\n",
        "        sentiment_class = 'negative'\n",
        "    else:\n",
        "        sentiment_class = 'neutral'\n",
        "\n",
        "    return polarity, sentiment_class\n",
        "\n",
        "# Example Usage:\n",
        "print(\"Example 1:\")\n",
        "text1 = \"This is a fantastic product! I absolutely love it.\"\n",
        "polarity1, sentiment1 = analyze_sentiment(text1)\n",
        "print(f\"Text: '{text1}'\")\n",
        "print(f\"Polarity: {polarity1:.2f}, Sentiment: {sentiment1}\")\n",
        "\n",
        "print(\"\\nExample 2:\")\n",
        "text2 = \"I am very disappointed with the service.\"\n",
        "polarity2, sentiment2 = analyze_sentiment(text2)\n",
        "print(f\"Text: '{text2}'\")\n",
        "print(f\"Polarity: {polarity2:.2f}, Sentiment: {sentiment2}\")\n",
        "\n",
        "print(\"\\nExample 3:\")\n",
        "text3 = \"The weather is neither good nor bad today.\"\n",
        "polarity3, sentiment3 = analyze_sentiment(text3)\n",
        "print(f\"Text: '{text3}'\")\n",
        "print(f\"Polarity: {polarity3:.2f}, Sentiment: {sentiment3}\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "Text: 'This is a fantastic product! I absolutely love it.'\n",
            "Polarity: 0.50, Sentiment: positive\n",
            "\n",
            "Example 2:\n",
            "Text: 'I am very disappointed with the service.'\n",
            "Polarity: -0.98, Sentiment: negative\n",
            "\n",
            "Example 3:\n",
            "Text: 'The weather is neither good nor bad today.'\n",
            "Polarity: 0.00, Sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUMMARY**\n",
        "\n",
        "Sentiment Analysis Function: A Python function analyze_sentiment was generated using TextBlob to determine the polarity and classification (positive, negative, neutral) of a given text.\n",
        "NLTK and TextBlob Setup: Necessary NLTK corpora and TextBlob were installed to facilitate the sentiment analysis.\n",
        "Bias Handling: The request to identify and handle potential biases in the data for sentiment analysis was not addressed by the generated code.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4muhUQSpBRnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task3"
      ],
      "metadata": {
        "id": "MwNNkZwo7ava"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4d973da0",
        "outputId": "270c95c4-3147-4b2d-c3ad-f8b3521e8e24"
      },
      "source": [
        "print(\"### browsing_history_df - First 5 rows:\")\n",
        "print(browsing_history_df.head())\n",
        "\n",
        "print(\"\\n### purchase_data_df - First 5 rows:\")\n",
        "print(purchase_data_df.head())\n",
        "\n",
        "print(\"\\n### products_df - First 5 rows:\")\n",
        "print(products_df.head())\n",
        "\n",
        "print(\"\\n### browsing_history_df - Info:\")\n",
        "browsing_history_df.info()\n",
        "\n",
        "print(\"\\n### purchase_data_df - Info:\")\n",
        "purchase_data_df.info()\n",
        "\n",
        "print(\"\\n### products_df - Info:\")\n",
        "products_df.info()\n",
        "\n",
        "print(\"\\n### Unique Categories in products_df:\")\n",
        "print(products_df['category'].unique())\n",
        "\n",
        "print(\"\\n### Unique Brands in products_df:\")\n",
        "print(products_df['brand'].unique())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### browsing_history_df - First 5 rows:\n",
            "  user_id product_id\n",
            "0    U008       P001\n",
            "1    U004       P003\n",
            "2    U006       P006\n",
            "3    U008       P004\n",
            "4    U010       P011\n",
            "\n",
            "### purchase_data_df - First 5 rows:\n",
            "  user_id product_id\n",
            "0    U005       P013\n",
            "1    U010       P004\n",
            "2    U006       P011\n",
            "3    U007       P007\n",
            "4    U002       P006\n",
            "\n",
            "### products_df - First 5 rows:\n",
            "  product_id        category   price   brand  rating\n",
            "0       P001  Home & Kitchen   19.85  BrandE     3.8\n",
            "1       P002     Electronics  371.09  BrandB     4.4\n",
            "2       P003           Books  274.66  BrandC     2.8\n",
            "3       P004        Clothing  324.52  BrandD     3.6\n",
            "4       P005     Electronics   48.65  BrandA     2.6\n",
            "\n",
            "### browsing_history_df - Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50 entries, 0 to 49\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   user_id     50 non-null     object\n",
            " 1   product_id  50 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 932.0+ bytes\n",
            "\n",
            "### purchase_data_df - Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25 entries, 0 to 24\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   user_id     25 non-null     object\n",
            " 1   product_id  25 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 532.0+ bytes\n",
            "\n",
            "### products_df - Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14 entries, 0 to 13\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   product_id  14 non-null     object \n",
            " 1   category    14 non-null     object \n",
            " 2   price       14 non-null     float64\n",
            " 3   brand       14 non-null     object \n",
            " 4   rating      14 non-null     float64\n",
            "dtypes: float64(2), object(3)\n",
            "memory usage: 692.0+ bytes\n",
            "\n",
            "### Unique Categories in products_df:\n",
            "['Home & Kitchen' 'Electronics' 'Books' 'Clothing' 'Sports']\n",
            "\n",
            "### Unique Brands in products_df:\n",
            "['BrandE' 'BrandB' 'BrandC' 'BrandD' 'BrandA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "55b05b5e",
        "outputId": "9b02652b-cf36-4320-85d9-088b6e556945"
      },
      "source": [
        "def get_raw_recommendations(user_id, browsing_history_df, purchase_data_df, products_df):\n",
        "    \"\"\"\n",
        "    Identifies products a user has browsed or purchased and generates raw recommendations\n",
        "    based on products the user has NOT interacted with.\n",
        "\n",
        "    Args:\n",
        "        user_id (str): The ID of the user for whom to generate recommendations.\n",
        "        browsing_history_df (pd.DataFrame): DataFrame containing user browsing history.\n",
        "        purchase_data_df (pd.DataFrame): DataFrame containing user purchase data.\n",
        "        products_df (pd.DataFrame): DataFrame containing all available product information.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of product_ids representing raw recommendations for the user.\n",
        "    \"\"\"\n",
        "    # Get products browsed by the user\n",
        "    browsed_products = set(browsing_history_df[browsing_history_df['user_id'] == user_id]['product_id'].unique())\n",
        "\n",
        "    # Get products purchased by the user\n",
        "    purchased_products = set(purchase_data_df[purchase_data_df['user_id'] == user_id]['product_id'].unique())\n",
        "\n",
        "    # Combine browsed and purchased products into a set of interacted products\n",
        "    interacted_products = browsed_products.union(purchased_products)\n",
        "\n",
        "    # Get all available product IDs\n",
        "    all_product_ids = set(products_df['product_id'].unique())\n",
        "\n",
        "    # Identify products the user has not interacted with\n",
        "    raw_recommendations = list(all_product_ids - interacted_products)\n",
        "\n",
        "    print(f\"\\nUser: {user_id}\")\n",
        "    print(f\"  Browsed products: {list(browsed_products)}\")\n",
        "    print(f\"  Purchased products: {list(purchased_products)}\")\n",
        "    print(f\"  Interacted products: {list(interacted_products)}\")\n",
        "    print(f\"  Raw recommendations (uninteracted products): {raw_recommendations}\")\n",
        "\n",
        "    return raw_recommendations\n",
        "\n",
        "# Example Usage:\n",
        "# Assuming 'U001' is a user we want recommendations for\n",
        "user_id_to_test = 'U001'\n",
        "raw_recs = get_raw_recommendations(user_id_to_test, browsing_history_df, purchase_data_df, products_df)\n",
        "\n",
        "user_id_to_test_2 = 'U004'\n",
        "raw_recs_2 = get_raw_recommendations(user_id_to_test_2, browsing_history_df, purchase_data_df, products_df)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: U001\n",
            "  Browsed products: ['P006', 'P005', 'P011', 'P009', 'P001', 'P010']\n",
            "  Purchased products: ['P005']\n",
            "  Interacted products: ['P009', 'P001', 'P006', 'P005', 'P010', 'P011']\n",
            "  Raw recommendations (uninteracted products): ['P003', 'P008', 'P002', 'P012', 'P004', 'P014', 'P013', 'P007']\n",
            "\n",
            "User: U004\n",
            "  Browsed products: ['P003', 'P008', 'P014', 'P007', 'P010']\n",
            "  Purchased products: []\n",
            "  Interacted products: ['P003', 'P014', 'P008', 'P007', 'P010']\n",
            "  Raw recommendations (uninteracted products): ['P006', 'P002', 'P005', 'P012', 'P011', 'P009', 'P004', 'P001', 'P013']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cb75d463",
        "outputId": "9008e22e-a7ce-4dce-dc48-52d0e46bb917"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_transparent_recommendations(user_id, browsing_history_df, purchase_data_df, products_df):\n",
        "    \"\"\"\n",
        "    Generates product recommendations with clear explanations for each.\n",
        "\n",
        "    Args:\n",
        "        user_id (str): The ID of the user for whom to generate recommendations.\n",
        "        browsing_history_df (pd.DataFrame): DataFrame containing user browsing history.\n",
        "        purchase_data_df (pd.DataFrame): DataFrame containing user purchase data.\n",
        "        products_df (pd.DataFrame): DataFrame containing all available product information.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each containing 'product_id' and a 'reason' for the recommendation.\n",
        "    \"\"\"\n",
        "    # 2. Identify all product_ids that the user has already browsed or purchased\n",
        "    browsed_products = set(browsing_history_df[browsing_history_df['user_id'] == user_id]['product_id'].unique())\n",
        "    purchased_products = set(purchase_data_df[purchase_data_df['user_id'] == user_id]['product_id'].unique())\n",
        "    interacted_product_ids = browsed_products.union(purchased_products)\n",
        "\n",
        "    # 3. Create a DataFrame candidate_products_df\n",
        "    candidate_products_df = products_df[~products_df['product_id'].isin(interacted_product_ids)].copy()\n",
        "\n",
        "    # 4a. Retrieve all products the user has browsed, including their categories\n",
        "    user_browsed_products = browsing_history_df[browsing_history_df['user_id'] == user_id].drop_duplicates(subset=['product_id'])\n",
        "    user_browsed_products_with_categories = pd.merge(user_browsed_products, products_df[['product_id', 'category']], on='product_id', how='left')\n",
        "\n",
        "    # 4b. Retrieve all products the user has purchased, including their categories\n",
        "    user_purchased_products = purchase_data_df[purchase_data_df['user_id'] == user_id].drop_duplicates(subset=['product_id'])\n",
        "    user_purchased_products_with_categories = pd.merge(user_purchased_products, products_df[['product_id', 'category']], on='product_id', how='left')\n",
        "\n",
        "    # 5. Initialize an empty list for transparent recommendations\n",
        "    transparent_recommendations = []\n",
        "\n",
        "    # 6. Iterate through each candidate product to generate a reason\n",
        "    for _, candidate_product in candidate_products_df.iterrows():\n",
        "        reason = \"Recommended based on general popularity.\"\n",
        "        candidate_category = candidate_product['category']\n",
        "\n",
        "        # 6b. Attempt to find a purchase-based reason\n",
        "        for _, purchased_item in user_purchased_products_with_categories.iterrows():\n",
        "            if purchased_item['category'] == candidate_category:\n",
        "                reason = f\"Recommended because you previously purchased product '{purchased_item['product_id']}' in the '{purchased_item['category']}' category.\"\n",
        "                break # Prioritize the first matching purchased item\n",
        "\n",
        "        # 6c. If no purchase reason, attempt to find a browsing-based reason\n",
        "        if reason == \"Recommended based on general popularity.\": # No purchase-based reason found\n",
        "            for _, browsed_item in user_browsed_products_with_categories.iterrows():\n",
        "                if browsed_item['category'] == candidate_category:\n",
        "                    reason = f\"Recommended because you previously browsed product '{browsed_item['product_id']}' in the '{browsed_item['category']}' category.\"\n",
        "                    break # Prioritize the first matching browsed item\n",
        "\n",
        "        # 6e. Append the recommendation\n",
        "        transparent_recommendations.append({\n",
        "            'product_id': candidate_product['product_id'],\n",
        "            'reason': reason\n",
        "        })\n",
        "\n",
        "    return transparent_recommendations\n",
        "\n",
        "# 8. Test the function\n",
        "user_id_to_recommend_1 = 'U001'\n",
        "user_recommendations = get_transparent_recommendations(user_id_to_recommend_1, browsing_history_df, purchase_data_df, products_df)\n",
        "print(f\"\\nTransparent Recommendations for {user_id_to_recommend_1}:\")\n",
        "for rec in user_recommendations:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n",
        "\n",
        "user_id_to_recommend_2 = 'U004'\n",
        "user_recommendations_2 = get_transparent_recommendations(user_id_to_recommend_2, browsing_history_df, purchase_data_df, products_df)\n",
        "print(f\"\\nTransparent Recommendations for {user_id_to_recommend_2}:\")\n",
        "for rec in user_recommendations_2:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transparent Recommendations for U001:\n",
            "  Product ID: P002, Reason: Recommended because you previously purchased product 'P005' in the 'Electronics' category.\n",
            "  Product ID: P003, Reason: Recommended based on general popularity.\n",
            "  Product ID: P004, Reason: Recommended because you previously browsed product 'P006' in the 'Clothing' category.\n",
            "  Product ID: P007, Reason: Recommended because you previously browsed product 'P001' in the 'Home & Kitchen' category.\n",
            "  Product ID: P008, Reason: Recommended because you previously browsed product 'P006' in the 'Clothing' category.\n",
            "  Product ID: P012, Reason: Recommended because you previously purchased product 'P005' in the 'Electronics' category.\n",
            "  Product ID: P013, Reason: Recommended because you previously browsed product 'P001' in the 'Home & Kitchen' category.\n",
            "  Product ID: P014, Reason: Recommended because you previously browsed product 'P009' in the 'Sports' category.\n",
            "\n",
            "Transparent Recommendations for U004:\n",
            "  Product ID: P001, Reason: Recommended because you previously browsed product 'P007' in the 'Home & Kitchen' category.\n",
            "  Product ID: P002, Reason: Recommended based on general popularity.\n",
            "  Product ID: P004, Reason: Recommended because you previously browsed product 'P008' in the 'Clothing' category.\n",
            "  Product ID: P005, Reason: Recommended based on general popularity.\n",
            "  Product ID: P006, Reason: Recommended because you previously browsed product 'P008' in the 'Clothing' category.\n",
            "  Product ID: P009, Reason: Recommended because you previously browsed product 'P010' in the 'Sports' category.\n",
            "  Product ID: P011, Reason: Recommended based on general popularity.\n",
            "  Product ID: P012, Reason: Recommended based on general popularity.\n",
            "  Product ID: P013, Reason: Recommended because you previously browsed product 'P007' in the 'Home & Kitchen' category.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b691b608",
        "outputId": "e2349c18-2b4a-4f2f-8623-7c284fd820a8"
      },
      "source": [
        "def get_fair_diverse_recommendations(\n",
        "    user_id,\n",
        "    browsing_history_df,\n",
        "    purchase_data_df,\n",
        "    products_df,\n",
        "    num_recommendations=5,\n",
        "    diversity_strength=0.5\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates product recommendations with enhanced diversity, ensuring a mix of personalized\n",
        "    and potentially new categories/brands.\n",
        "\n",
        "    Args:\n",
        "        user_id (str): The ID of the user for whom to generate recommendations.\n",
        "        browsing_history_df (pd.DataFrame): DataFrame containing user browsing history.\n",
        "        purchase_data_df (pd.DataFrame): DataFrame containing user purchase data.\n",
        "        products_df (pd.DataFrame): DataFrame containing all available product information.\n",
        "        num_recommendations (int): The total number of recommendations to return.\n",
        "        diversity_strength (float): A value between 0 and 1, where a higher value prioritizes\n",
        "                                    more diverse (uninteracted category/brand) recommendations.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each containing 'product_id' and a 'reason'.\n",
        "    \"\"\"\n",
        "    # 1. Get initial transparent recommendations\n",
        "    transparent_recs = get_transparent_recommendations(user_id, browsing_history_df, purchase_data_df, products_df)\n",
        "\n",
        "    # 2. Identify all unique categories and brands the user has interacted with\n",
        "    user_browsed_products = browsing_history_df[browsing_history_df['user_id'] == user_id]['product_id'].unique()\n",
        "    user_purchased_products = purchase_data_df[purchase_data_df['user_id'] == user_id]['product_id'].unique()\n",
        "\n",
        "    interacted_product_ids = set(list(user_browsed_products) + list(user_purchased_products))\n",
        "\n",
        "    interacted_categories = products_df[products_df['product_id'].isin(interacted_product_ids)]['category'].unique()\n",
        "    interacted_brands = products_df[products_df['product_id'].isin(interacted_product_ids)]['brand'].unique()\n",
        "\n",
        "    # 3. Initialize candidate lists\n",
        "    diverse_recommendations_candidates = []\n",
        "    personalized_recommendations_candidates = []\n",
        "    seen_product_ids = set()\n",
        "\n",
        "    # 4. Iterate and categorize recommendations\n",
        "    for rec in transparent_recs:\n",
        "        product_id = rec['product_id']\n",
        "        if product_id in seen_product_ids:\n",
        "            continue\n",
        "        seen_product_ids.add(product_id)\n",
        "\n",
        "        product_info = products_df[products_df['product_id'] == product_id].iloc[0]\n",
        "        product_category = product_info['category']\n",
        "        product_brand = product_info['brand']\n",
        "\n",
        "        # Check if the product's category or brand is new to the user's interactions\n",
        "        is_diverse = (product_category not in interacted_categories) or \\\n",
        "                     (product_brand not in interacted_brands)\n",
        "\n",
        "        if is_diverse:\n",
        "            diverse_recommendations_candidates.append(rec)\n",
        "        else:\n",
        "            personalized_recommendations_candidates.append(rec)\n",
        "\n",
        "    # 5. Create the final list of diverse recommendations\n",
        "    final_recommendations = []\n",
        "    num_diverse_to_prioritize = int(num_recommendations * diversity_strength)\n",
        "\n",
        "    # Add diverse recommendations first\n",
        "    for i in range(min(num_diverse_to_prioritize, len(diverse_recommendations_candidates))):\n",
        "        final_recommendations.append(diverse_recommendations_candidates[i])\n",
        "\n",
        "    # Add personalized recommendations to fill up remaining slots\n",
        "    for i in range(min(num_recommendations - len(final_recommendations), len(personalized_recommendations_candidates))):\n",
        "        final_recommendations.append(personalized_recommendations_candidates[i])\n",
        "\n",
        "    # If still not enough, add more diverse recommendations (if available)\n",
        "    if len(final_recommendations) < num_recommendations:\n",
        "        remaining_needed = num_recommendations - len(final_recommendations)\n",
        "        start_index = min(num_diverse_to_prioritize, len(diverse_recommendations_candidates))\n",
        "        for i in range(start_index, min(start_index + remaining_needed, len(diverse_recommendations_candidates))):\n",
        "            final_recommendations.append(diverse_recommendations_candidates[i])\n",
        "\n",
        "    return final_recommendations[:num_recommendations]\n",
        "\n",
        "# Test the function\n",
        "print(\"\\n--- Testing with user U001 ---\")\n",
        "user_id_test_1 = 'U001'\n",
        "\n",
        "print(\"\\nRecommendations for U001 (Diversity Strength = 0.0 - Personalized Priority):\")\n",
        "recs_u001_no_diverse = get_fair_diverse_recommendations(user_id_test_1, browsing_history_df, purchase_data_df, products_df, diversity_strength=0.0, num_recommendations=5)\n",
        "for rec in recs_u001_no_diverse:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n",
        "\n",
        "print(\"\\nRecommendations for U001 (Diversity Strength = 0.7 - Diverse Priority):\")\n",
        "recs_u001_diverse = get_fair_diverse_recommendations(user_id_test_1, browsing_history_df, purchase_data_df, products_df, diversity_strength=0.7, num_recommendations=5)\n",
        "for rec in recs_u001_diverse:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n",
        "\n",
        "print(\"\\n--- Testing with user U009 ---\")\n",
        "user_id_test_2 = 'U009'\n",
        "\n",
        "print(\"\\nRecommendations for U009 (Diversity Strength = 0.0 - Personalized Priority):\")\n",
        "recs_u009_no_diverse = get_fair_diverse_recommendations(user_id_test_2, browsing_history_df, purchase_data_df, products_df, diversity_strength=0.0, num_recommendations=5)\n",
        "for rec in recs_u009_no_diverse:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n",
        "\n",
        "print(\"\\nRecommendations for U009 (Diversity Strength = 0.7 - Diverse Priority):\")\n",
        "recs_u009_diverse = get_fair_diverse_recommendations(user_id_test_2, browsing_history_df, purchase_data_df, products_df, diversity_strength=0.7, num_recommendations=5)\n",
        "for rec in recs_u009_diverse:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing with user U001 ---\n",
            "\n",
            "Recommendations for U001 (Diversity Strength = 0.0 - Personalized Priority):\n",
            "  Product ID: P002, Reason: Recommended because you previously purchased product 'P005' in the 'Electronics' category.\n",
            "  Product ID: P004, Reason: Recommended because you previously browsed product 'P006' in the 'Clothing' category.\n",
            "  Product ID: P007, Reason: Recommended because you previously browsed product 'P001' in the 'Home & Kitchen' category.\n",
            "  Product ID: P008, Reason: Recommended because you previously browsed product 'P006' in the 'Clothing' category.\n",
            "  Product ID: P012, Reason: Recommended because you previously purchased product 'P005' in the 'Electronics' category.\n",
            "\n",
            "Recommendations for U001 (Diversity Strength = 0.7 - Diverse Priority):\n",
            "  Product ID: P003, Reason: Recommended based on general popularity.\n",
            "  Product ID: P014, Reason: Recommended because you previously browsed product 'P009' in the 'Sports' category.\n",
            "  Product ID: P002, Reason: Recommended because you previously purchased product 'P005' in the 'Electronics' category.\n",
            "  Product ID: P004, Reason: Recommended because you previously browsed product 'P006' in the 'Clothing' category.\n",
            "  Product ID: P007, Reason: Recommended because you previously browsed product 'P001' in the 'Home & Kitchen' category.\n",
            "\n",
            "--- Testing with user U009 ---\n",
            "\n",
            "Recommendations for U009 (Diversity Strength = 0.0 - Personalized Priority):\n",
            "  Product ID: P001, Reason: Recommended because you previously purchased product 'P013' in the 'Home & Kitchen' category.\n",
            "  Product ID: P002, Reason: Recommended because you previously purchased product 'P012' in the 'Electronics' category.\n",
            "  Product ID: P005, Reason: Recommended because you previously purchased product 'P012' in the 'Electronics' category.\n",
            "  Product ID: P007, Reason: Recommended because you previously purchased product 'P013' in the 'Home & Kitchen' category.\n",
            "  Product ID: P009, Reason: Recommended because you previously browsed product 'P010' in the 'Sports' category.\n",
            "\n",
            "Recommendations for U009 (Diversity Strength = 0.7 - Diverse Priority):\n",
            "  Product ID: P004, Reason: Recommended because you previously purchased product 'P008' in the 'Clothing' category.\n",
            "  Product ID: P011, Reason: Recommended because you previously purchased product 'P012' in the 'Electronics' category.\n",
            "  Product ID: P001, Reason: Recommended because you previously purchased product 'P013' in the 'Home & Kitchen' category.\n",
            "  Product ID: P002, Reason: Recommended because you previously purchased product 'P012' in the 'Electronics' category.\n",
            "  Product ID: P005, Reason: Recommended because you previously purchased product 'P012' in the 'Electronics' category.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUMMARY**\n",
        "\n",
        "GitHub Copilot was used to generate a Python program that recommends products based on a userâ€™s past interactions or purchase history. The program analyzes user history to suggest relevant items using simple logic or similarity-based rules.\n",
        "\n",
        "While prompting Copilot, ethical guidelines such as transparency and fairness were explicitly included. Transparency ensures that the recommendation logic is easy to understand and explain to users, avoiding black-box behavior. Fairness ensures that recommendations do not favor or discriminate against specific products or user groups and treat all users equally based on relevant data only."
      ],
      "metadata": {
        "id": "aOy57vO2B3-V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4c73d36c",
        "outputId": "b2a4e24b-4d01-461a-8a19-96c95f238ad5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# --- 1. Generate Product Data ---\n",
        "product_ids = [f'P{i:03d}' for i in range(1, 15)] # 14 products\n",
        "categories = ['Electronics', 'Books', 'Clothing', 'Home & Kitchen', 'Sports']\n",
        "brands = ['BrandA', 'BrandB', 'BrandC', 'BrandD', 'BrandE']\n",
        "\n",
        "products_data = {\n",
        "    'product_id': product_ids,\n",
        "    'category': np.random.choice(categories, size=len(product_ids)),\n",
        "    'price': np.round(np.random.uniform(10, 500, size=len(product_ids)), 2),\n",
        "    'brand': np.random.choice(brands, size=len(product_ids)),\n",
        "    'rating': np.round(np.random.uniform(2.5, 4.9, size=len(product_ids)), 1)\n",
        "}\n",
        "products_df = pd.DataFrame(products_data)\n",
        "\n",
        "# --- 2. Generate User Browsing History Data ---\n",
        "num_users = 10\n",
        "user_ids = [f'U{i:03d}' for i in range(1, num_users + 1)]\n",
        "num_browsing_entries = 50\n",
        "\n",
        "user_ids_browse = np.random.choice(user_ids, size=num_browsing_entries)\n",
        "product_ids_browse = np.random.choice(product_ids, size=num_browsing_entries)\n",
        "browsing_history_df = pd.DataFrame({\n",
        "    'user_id': user_ids_browse,\n",
        "    'product_id': product_ids_browse\n",
        "})\n",
        "\n",
        "# --- 3. Generate User Purchase Data ---\n",
        "num_purchase_entries = 25\n",
        "\n",
        "user_ids_purchase = np.random.choice(user_ids, size=num_purchase_entries)\n",
        "product_ids_purchase = np.random.choice(product_ids, size=num_purchase_entries)\n",
        "purchase_data_df = pd.DataFrame({\n",
        "    'user_id': user_ids_purchase,\n",
        "    'product_id': product_ids_purchase\n",
        "})\n",
        "\n",
        "print(\"Dummy data generated successfully:\")\n",
        "print(f\"  Products: {len(products_df)} unique products\")\n",
        "print(f\"  Browsing History: {len(browsing_history_df)} entries\")\n",
        "print(f\"  Purchase Data: {len(purchase_data_df)} entries\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy data generated successfully:\n",
            "  Products: 14 unique products\n",
            "  Browsing History: 50 entries\n",
            "  Purchase Data: 25 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1399
        },
        "id": "72ca7be5",
        "outputId": "f2f1933a-c4a7-4367-8387-dcc103ef3cf9"
      },
      "source": [
        "print(\"### browsing_history_df - First 5 rows:\")\n",
        "display(browsing_history_df.head())\n",
        "\n",
        "print(\"\\n### purchase_data_df - First 5 rows:\")\n",
        "display(purchase_data_df.head())\n",
        "\n",
        "print(\"\\n### products_df - First 5 rows:\")\n",
        "display(products_df.head())\n",
        "\n",
        "print(\"\\n### browsing_history_df - Info:\")\n",
        "browsing_history_df.info()\n",
        "\n",
        "print(\"\\n### purchase_data_df - Info:\")\n",
        "purchase_data_df.info()\n",
        "\n",
        "print(\"\\n### products_df - Info:\")\n",
        "products_df.info()\n",
        "\n",
        "print(\"\\n### Unique Categories in products_df:\")\n",
        "print(products_df['category'].unique())\n",
        "\n",
        "print(\"\\n### Unique Brands in products_df:\")\n",
        "print(products_df['brand'].unique())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### browsing_history_df - First 5 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  user_id product_id\n",
              "0    U002       P005\n",
              "1    U010       P014\n",
              "2    U002       P003\n",
              "3    U010       P001\n",
              "4    U004       P005"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6e3f951-83cb-4692-890a-5c91a46c958d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>product_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>U002</td>\n",
              "      <td>P005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U010</td>\n",
              "      <td>P014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U002</td>\n",
              "      <td>P003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U010</td>\n",
              "      <td>P001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>U004</td>\n",
              "      <td>P005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6e3f951-83cb-4692-890a-5c91a46c958d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6e3f951-83cb-4692-890a-5c91a46c958d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6e3f951-83cb-4692-890a-5c91a46c958d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(products_df['brand']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"U002\",\n          \"U010\",\n          \"U004\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"P014\",\n          \"P001\",\n          \"P005\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### purchase_data_df - First 5 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  user_id product_id\n",
              "0    U010       P014\n",
              "1    U007       P001\n",
              "2    U009       P010\n",
              "3    U007       P004\n",
              "4    U001       P012"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a23b547-c19a-4b94-83e8-083086436ad9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>product_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>U010</td>\n",
              "      <td>P014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U007</td>\n",
              "      <td>P001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U009</td>\n",
              "      <td>P010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U007</td>\n",
              "      <td>P004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>U001</td>\n",
              "      <td>P012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a23b547-c19a-4b94-83e8-083086436ad9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a23b547-c19a-4b94-83e8-083086436ad9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a23b547-c19a-4b94-83e8-083086436ad9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(products_df['brand']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"U007\",\n          \"U001\",\n          \"U010\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"P001\",\n          \"P012\",\n          \"P010\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### products_df - First 5 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  product_id        category   price   brand  rating\n",
              "0       P001  Home & Kitchen  363.78  BrandC     3.4\n",
              "1       P002          Sports  469.89  BrandD     2.5\n",
              "2       P003        Clothing   10.38  BrandD     3.1\n",
              "3       P004          Sports  496.18  BrandA     3.1\n",
              "4       P005          Sports  312.57  BrandC     4.1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0be7ef6c-02c1-4a21-b4ad-819ad9dfb0c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>category</th>\n",
              "      <th>price</th>\n",
              "      <th>brand</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P001</td>\n",
              "      <td>Home &amp; Kitchen</td>\n",
              "      <td>363.78</td>\n",
              "      <td>BrandC</td>\n",
              "      <td>3.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P002</td>\n",
              "      <td>Sports</td>\n",
              "      <td>469.89</td>\n",
              "      <td>BrandD</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P003</td>\n",
              "      <td>Clothing</td>\n",
              "      <td>10.38</td>\n",
              "      <td>BrandD</td>\n",
              "      <td>3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P004</td>\n",
              "      <td>Sports</td>\n",
              "      <td>496.18</td>\n",
              "      <td>BrandA</td>\n",
              "      <td>3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P005</td>\n",
              "      <td>Sports</td>\n",
              "      <td>312.57</td>\n",
              "      <td>BrandC</td>\n",
              "      <td>4.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0be7ef6c-02c1-4a21-b4ad-819ad9dfb0c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0be7ef6c-02c1-4a21-b4ad-819ad9dfb0c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0be7ef6c-02c1-4a21-b4ad-819ad9dfb0c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(products_df['brand']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"product_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"P002\",\n          \"P005\",\n          \"P003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Home & Kitchen\",\n          \"Sports\",\n          \"Clothing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 194.15539794195783,\n        \"min\": 10.38,\n        \"max\": 496.18,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          469.89,\n          312.57,\n          10.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"BrandC\",\n          \"BrandD\",\n          \"BrandA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5813776741499452,\n        \"min\": 2.5,\n        \"max\": 4.1,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.5,\n          4.1,\n          3.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### browsing_history_df - Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50 entries, 0 to 49\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   user_id     50 non-null     object\n",
            " 1   product_id  50 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 932.0+ bytes\n",
            "\n",
            "### purchase_data_df - Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25 entries, 0 to 24\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   user_id     25 non-null     object\n",
            " 1   product_id  25 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 532.0+ bytes\n",
            "\n",
            "### products_df - Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14 entries, 0 to 13\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   product_id  14 non-null     object \n",
            " 1   category    14 non-null     object \n",
            " 2   price       14 non-null     float64\n",
            " 3   brand       14 non-null     object \n",
            " 4   rating      14 non-null     float64\n",
            "dtypes: float64(2), object(3)\n",
            "memory usage: 692.0+ bytes\n",
            "\n",
            "### Unique Categories in products_df:\n",
            "['Home & Kitchen' 'Sports' 'Clothing' 'Books']\n",
            "\n",
            "### Unique Brands in products_df:\n",
            "['BrandC' 'BrandD' 'BrandA' 'BrandE' 'BrandB']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b744c1c2",
        "outputId": "f6e1dae0-7732-4d90-f386-a43623df45bf"
      },
      "source": [
        "def get_raw_recommendations(user_id, browsing_history_df, purchase_data_df, products_df):\n",
        "    \"\"\"\n",
        "    Identifies products a user has browsed or purchased and generates raw recommendations\n",
        "    based on products the user has NOT interacted with.\n",
        "\n",
        "    Args:\n",
        "        user_id (str): The ID of the user for whom to generate recommendations.\n",
        "        browsing_history_df (pd.DataFrame): DataFrame containing user browsing history.\n",
        "        purchase_data_df (pd.DataFrame): DataFrame containing user purchase data.\n",
        "        products_df (pd.DataFrame): DataFrame containing all available product information.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of product_ids representing raw recommendations for the user.\n",
        "    \"\"\"\n",
        "    # Get products browsed by the user\n",
        "    browsed_products = set(browsing_history_df[browsing_history_df['user_id'] == user_id]['product_id'].unique())\n",
        "\n",
        "    # Get products purchased by the user\n",
        "    purchased_products = set(purchase_data_df[purchase_data_df['user_id'] == user_id]['product_id'].unique())\n",
        "\n",
        "    # Combine browsed and purchased products into a set of interacted products\n",
        "    interacted_products = browsed_products.union(purchased_products)\n",
        "\n",
        "    # Get all available product IDs\n",
        "    all_product_ids = set(products_df['product_id'].unique())\n",
        "\n",
        "    # Identify products the user has not interacted with\n",
        "    raw_recommendations = list(all_product_ids - interacted_products)\n",
        "\n",
        "    print(f\"\\nUser: {user_id}\")\n",
        "    print(f\"  Browsed products: {list(browsed_products)}\")\n",
        "    print(f\"  Purchased products: {list(purchased_products)}\")\n",
        "    print(f\"  Interacted products: {list(interacted_products)}\")\n",
        "    print(f\"  Raw recommendations (uninteracted products): {raw_recommendations}\")\n",
        "\n",
        "    return raw_recommendations\n",
        "\n",
        "# Example Usage:\n",
        "# Assuming 'U001' is a user we want recommendations for\n",
        "user_id_to_test = 'U001'\n",
        "raw_recs = get_raw_recommendations(user_id_to_test, browsing_history_df, purchase_data_df, products_df)\n",
        "\n",
        "user_id_to_test_2 = 'U004'\n",
        "raw_recs_2 = get_raw_recommendations(user_id_to_test_2, browsing_history_df, purchase_data_df, products_df)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: U001\n",
            "  Browsed products: ['P014', 'P009', 'P013', 'P007']\n",
            "  Purchased products: ['P002', 'P003', 'P014', 'P012']\n",
            "  Interacted products: ['P003', 'P002', 'P012', 'P009', 'P014', 'P013', 'P007']\n",
            "  Raw recommendations (uninteracted products): ['P006', 'P008', 'P005', 'P011', 'P004', 'P001', 'P010']\n",
            "\n",
            "User: U004\n",
            "  Browsed products: ['P005']\n",
            "  Purchased products: ['P003', 'P001']\n",
            "  Interacted products: ['P003', 'P005', 'P001']\n",
            "  Raw recommendations (uninteracted products): ['P006', 'P002', 'P008', 'P012', 'P011', 'P009', 'P004', 'P014', 'P013', 'P007', 'P010']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2a10c8a1",
        "outputId": "1d39920b-d9f3-40b1-e891-dcc886839b09"
      },
      "source": [
        "def get_transparent_recommendations(user_id, browsing_history_df, purchase_data_df, products_df):\n",
        "    \"\"\"\n",
        "    Generates product recommendations with clear explanations for each.\n",
        "\n",
        "    Args:\n",
        "        user_id (str): The ID of the user for whom to generate recommendations.\n",
        "        browsing_history_df (pd.DataFrame): DataFrame containing user browsing history.\n",
        "        purchase_data_df (pd.DataFrame): DataFrame containing user purchase data.\n",
        "        products_df (pd.DataFrame): DataFrame containing all available product information.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each containing 'product_id' and a 'reason' for the recommendation.\n",
        "    \"\"\"\n",
        "    # 2. Identify all product_ids that the user has already browsed or purchased\n",
        "    browsed_products = set(browsing_history_df[browsing_history_df['user_id'] == user_id]['product_id'].unique())\n",
        "    purchased_products = set(purchase_data_df[purchase_data_df['user_id'] == user_id]['product_id'].unique())\n",
        "    interacted_product_ids = browsed_products.union(purchased_products)\n",
        "\n",
        "    # 3. Create a DataFrame candidate_products_df\n",
        "    candidate_products_df = products_df[~products_df['product_id'].isin(interacted_product_ids)].copy()\n",
        "\n",
        "    # 4a. Retrieve all products the user has browsed, including their categories\n",
        "    user_browsed_products = browsing_history_df[browsing_history_df['user_id'] == user_id].drop_duplicates(subset=['product_id'])\n",
        "    user_browsed_products_with_categories = pd.merge(user_browsed_products, products_df[['product_id', 'category']], on='product_id', how='left')\n",
        "\n",
        "    # 4b. Retrieve all products the user has purchased, including their categories\n",
        "    user_purchased_products = purchase_data_df[purchase_data_df['user_id'] == user_id].drop_duplicates(subset=['product_id'])\n",
        "    user_purchased_products_with_categories = pd.merge(user_purchased_products, products_df[['product_id', 'category']], on='product_id', how='left')\n",
        "\n",
        "    # 5. Initialize an empty list for transparent recommendations\n",
        "    transparent_recommendations = []\n",
        "\n",
        "    # 6. Iterate through each candidate product to generate a reason\n",
        "    for _, candidate_product in candidate_products_df.iterrows():\n",
        "        reason = \"Recommended based on general popularity.\"\n",
        "        candidate_category = candidate_product['category']\n",
        "\n",
        "        # 6b. Attempt to find a purchase-based reason\n",
        "        for _, purchased_item in user_purchased_products_with_categories.iterrows():\n",
        "            if purchased_item['category'] == candidate_category:\n",
        "                reason = f\"Recommended because you previously purchased product '{purchased_item['product_id']}' in the '{purchased_item['category']}' category.\"\n",
        "                break # Prioritize the first matching purchased item\n",
        "\n",
        "        # 6c. If no purchase reason, attempt to find a browsing-based reason\n",
        "        if reason == \"Recommended based on general popularity.\": # No purchase-based reason found\n",
        "            for _, browsed_item in user_browsed_products_with_categories.iterrows():\n",
        "                if browsed_item['category'] == candidate_category:\n",
        "                    reason = f\"Recommended because you previously browsed product '{browsed_item['product_id']}' in the '{browsed_item['category']}' category.\"\n",
        "                    break # Prioritize the first matching browsed item\n",
        "\n",
        "        # 6e. Append the recommendation\n",
        "        transparent_recommendations.append({\n",
        "            'product_id': candidate_product['product_id'],\n",
        "            'reason': reason\n",
        "        })\n",
        "\n",
        "    return transparent_recommendations\n",
        "\n",
        "# 8. Test the function\n",
        "user_id_to_recommend_1 = 'U001'\n",
        "user_recommendations = get_transparent_recommendations(user_id_to_recommend_1, browsing_history_df, purchase_data_df, products_df)\n",
        "print(f\"\\nTransparent Recommendations for {user_id_to_recommend_1}:\")\n",
        "for rec in user_recommendations:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n",
        "\n",
        "user_id_to_recommend_2 = 'U004'\n",
        "user_recommendations_2 = get_transparent_recommendations(user_id_to_recommend_2, browsing_history_df, purchase_data_df, products_df)\n",
        "print(f\"\\nTransparent Recommendations for {user_id_to_recommend_2}:\")\n",
        "for rec in user_recommendations_2:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transparent Recommendations for U001:\n",
            "  Product ID: P001, Reason: Recommended based on general popularity.\n",
            "  Product ID: P004, Reason: Recommended because you previously purchased product 'P002' in the 'Sports' category.\n",
            "  Product ID: P005, Reason: Recommended because you previously purchased product 'P002' in the 'Sports' category.\n",
            "  Product ID: P006, Reason: Recommended because you previously purchased product 'P014' in the 'Books' category.\n",
            "  Product ID: P008, Reason: Recommended because you previously purchased product 'P012' in the 'Clothing' category.\n",
            "  Product ID: P010, Reason: Recommended because you previously purchased product 'P002' in the 'Sports' category.\n",
            "  Product ID: P011, Reason: Recommended based on general popularity.\n",
            "\n",
            "Transparent Recommendations for U004:\n",
            "  Product ID: P002, Reason: Recommended because you previously browsed product 'P005' in the 'Sports' category.\n",
            "  Product ID: P004, Reason: Recommended because you previously browsed product 'P005' in the 'Sports' category.\n",
            "  Product ID: P006, Reason: Recommended based on general popularity.\n",
            "  Product ID: P007, Reason: Recommended because you previously purchased product 'P003' in the 'Clothing' category.\n",
            "  Product ID: P008, Reason: Recommended because you previously purchased product 'P003' in the 'Clothing' category.\n",
            "  Product ID: P009, Reason: Recommended because you previously purchased product 'P003' in the 'Clothing' category.\n",
            "  Product ID: P010, Reason: Recommended because you previously browsed product 'P005' in the 'Sports' category.\n",
            "  Product ID: P011, Reason: Recommended because you previously purchased product 'P001' in the 'Home & Kitchen' category.\n",
            "  Product ID: P012, Reason: Recommended because you previously purchased product 'P003' in the 'Clothing' category.\n",
            "  Product ID: P013, Reason: Recommended because you previously browsed product 'P005' in the 'Sports' category.\n",
            "  Product ID: P014, Reason: Recommended based on general popularity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "be7a36ac",
        "outputId": "77865d33-9b22-4237-9626-6b14e20a6c56"
      },
      "source": [
        "def get_fair_diverse_recommendations(\n",
        "    user_id,\n",
        "    browsing_history_df,\n",
        "    purchase_data_df,\n",
        "    products_df,\n",
        "    num_recommendations=5,\n",
        "    diversity_strength=0.5\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates product recommendations with enhanced diversity, ensuring a mix of personalized\n",
        "    and potentially new categories/brands.\n",
        "\n",
        "    Args:\n",
        "        user_id (str): The ID of the user for whom to generate recommendations.\n",
        "        browsing_history_df (pd.DataFrame): DataFrame containing user browsing history.\n",
        "        purchase_data_df (pd.DataFrame): DataFrame containing user purchase data.\n",
        "        products_df (pd.DataFrame): DataFrame containing all available product information.\n",
        "        num_recommendations (int): The total number of recommendations to return.\n",
        "        diversity_strength (float): A value between 0 and 1, where a higher value prioritizes\n",
        "                                    more diverse (uninteracted category/brand) recommendations.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each containing 'product_id' and a 'reason'.\n",
        "    \"\"\"\n",
        "    # 1. Get initial transparent recommendations\n",
        "    transparent_recs = get_transparent_recommendations(user_id, browsing_history_df, purchase_data_df, products_df)\n",
        "\n",
        "    # 2. Identify all unique categories and brands the user has interacted with\n",
        "    user_browsed_products = browsing_history_df[browsing_history_df['user_id'] == user_id]['product_id'].unique()\n",
        "    user_purchased_products = purchase_data_df[purchase_data_df['user_id'] == user_id]['product_id'].unique()\n",
        "\n",
        "    interacted_product_ids = set(list(user_browsed_products) + list(user_purchased_products))\n",
        "\n",
        "    interacted_categories = products_df[products_df['product_id'].isin(interacted_product_ids)]['category'].unique()\n",
        "    interacted_brands = products_df[products_df['product_id'].isin(interacted_product_ids)]['brand'].unique()\n",
        "\n",
        "    # 3. Initialize candidate lists\n",
        "    diverse_recommendations_candidates = []\n",
        "    personalized_recommendations_candidates = []\n",
        "    seen_product_ids = set()\n",
        "\n",
        "    # 4. Iterate and categorize recommendations\n",
        "    for rec in transparent_recs:\n",
        "        product_id = rec['product_id']\n",
        "        if product_id in seen_product_ids:\n",
        "            continue\n",
        "        seen_product_ids.add(product_id)\n",
        "\n",
        "        product_info = products_df[products_df['product_id'] == product_id].iloc[0]\n",
        "        product_category = product_info['category']\n",
        "        product_brand = product_info['brand']\n",
        "\n",
        "        # Check if the product's category or brand is new to the user's interactions\n",
        "        is_diverse = (product_category not in interacted_categories) or \\\n",
        "                     (product_brand not in interacted_brands)\n",
        "\n",
        "        if is_diverse:\n",
        "            diverse_recommendations_candidates.append(rec)\n",
        "        else:\n",
        "            personalized_recommendations_candidates.append(rec)\n",
        "\n",
        "    # 5. Create the final list of diverse recommendations\n",
        "    final_recommendations = []\n",
        "    num_diverse_to_prioritize = int(num_recommendations * diversity_strength)\n",
        "\n",
        "    # Add diverse recommendations first\n",
        "    for i in range(min(num_diverse_to_prioritize, len(diverse_recommendations_candidates))):\n",
        "        final_recommendations.append(diverse_recommendations_candidates[i])\n",
        "\n",
        "    # Add personalized recommendations to fill up remaining slots\n",
        "    for i in range(min(num_recommendations - len(final_recommendations), len(personalized_recommendations_candidates))):\n",
        "        final_recommendations.append(personalized_recommendations_candidates[i])\n",
        "\n",
        "    # If still not enough, add more diverse recommendations (if available)\n",
        "    if len(final_recommendations) < num_recommendations:\n",
        "        remaining_needed = num_recommendations - len(final_recommendations)\n",
        "        start_index = min(num_diverse_to_prioritize, len(diverse_recommendations_candidates))\n",
        "        for i in range(start_index, min(start_index + remaining_needed, len(diverse_recommendations_candidates))):\n",
        "            final_recommendations.append(diverse_recommendations_candidates[i])\n",
        "\n",
        "    return final_recommendations[:num_recommendations]\n",
        "\n",
        "# Test the function\n",
        "print(\"\\n--- Testing with user U001 ---\")\n",
        "user_id_test_1 = 'U001'\n",
        "\n",
        "print(\"\\nRecommendations for U001 (Diversity Strength = 0.0 - Personalized Priority):\")\n",
        "recs_u001_no_diverse = get_fair_diverse_recommendations(user_id_test_1, browsing_history_df, purchase_data_df, products_df, diversity_strength=0.0, num_recommendations=5)\n",
        "for rec in recs_u001_no_diverse:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n",
        "\n",
        "print(\"\\nRecommendations for U001 (Diversity Strength = 0.7 - Diverse Priority):\")\n",
        "recs_u001_diverse = get_fair_diverse_recommendations(user_id_test_1, browsing_history_df, purchase_data_df, products_df, diversity_strength=0.7, num_recommendations=5)\n",
        "for rec in recs_u001_diverse:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n",
        "\n",
        "print(\"\\n--- Testing with user U009 ---\")\n",
        "user_id_test_2 = 'U009'\n",
        "\n",
        "print(\"\\nRecommendations for U009 (Diversity Strength = 0.0 - Personalized Priority):\")\n",
        "recs_u009_no_diverse = get_fair_diverse_recommendations(user_id_test_2, browsing_history_df, purchase_data_df, products_df, diversity_strength=0.0, num_recommendations=5)\n",
        "for rec in recs_u009_no_diverse:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")\n",
        "\n",
        "print(\"\\nRecommendations for U009 (Diversity Strength = 0.7 - Diverse Priority):\")\n",
        "recs_u009_diverse = get_fair_diverse_recommendations(user_id_test_2, browsing_history_df, purchase_data_df, products_df, diversity_strength=0.7, num_recommendations=5)\n",
        "for rec in recs_u009_diverse:\n",
        "    print(f\"  Product ID: {rec['product_id']}, Reason: {rec['reason']}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing with user U001 ---\n",
            "\n",
            "Recommendations for U001 (Diversity Strength = 0.0 - Personalized Priority):\n",
            "  Product ID: P004, Reason: Recommended because you previously purchased product 'P002' in the 'Sports' category.\n",
            "  Product ID: P005, Reason: Recommended because you previously purchased product 'P002' in the 'Sports' category.\n",
            "  Product ID: P010, Reason: Recommended because you previously purchased product 'P002' in the 'Sports' category.\n",
            "  Product ID: P001, Reason: Recommended based on general popularity.\n",
            "  Product ID: P006, Reason: Recommended because you previously purchased product 'P014' in the 'Books' category.\n",
            "\n",
            "Recommendations for U001 (Diversity Strength = 0.7 - Diverse Priority):\n",
            "  Product ID: P001, Reason: Recommended based on general popularity.\n",
            "  Product ID: P006, Reason: Recommended because you previously purchased product 'P014' in the 'Books' category.\n",
            "  Product ID: P008, Reason: Recommended because you previously purchased product 'P012' in the 'Clothing' category.\n",
            "  Product ID: P004, Reason: Recommended because you previously purchased product 'P002' in the 'Sports' category.\n",
            "  Product ID: P005, Reason: Recommended because you previously purchased product 'P002' in the 'Sports' category.\n",
            "\n",
            "--- Testing with user U009 ---\n",
            "\n",
            "Recommendations for U009 (Diversity Strength = 0.0 - Personalized Priority):\n",
            "  Product ID: P004, Reason: Recommended because you previously purchased product 'P010' in the 'Sports' category.\n",
            "  Product ID: P005, Reason: Recommended because you previously purchased product 'P010' in the 'Sports' category.\n",
            "  Product ID: P009, Reason: Recommended because you previously purchased product 'P007' in the 'Clothing' category.\n",
            "  Product ID: P006, Reason: Recommended because you previously browsed product 'P014' in the 'Books' category.\n",
            "  Product ID: P008, Reason: Recommended because you previously purchased product 'P007' in the 'Clothing' category.\n",
            "\n",
            "Recommendations for U009 (Diversity Strength = 0.7 - Diverse Priority):\n",
            "  Product ID: P006, Reason: Recommended because you previously browsed product 'P014' in the 'Books' category.\n",
            "  Product ID: P008, Reason: Recommended because you previously purchased product 'P007' in the 'Clothing' category.\n",
            "  Product ID: P004, Reason: Recommended because you previously purchased product 'P010' in the 'Sports' category.\n",
            "  Product ID: P005, Reason: Recommended because you previously purchased product 'P010' in the 'Sports' category.\n",
            "  Product ID: P009, Reason: Recommended because you previously purchased product 'P007' in the 'Clothing' category.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUMMARY**\n",
        "\n",
        "GitHub Copilot was prompted to add logging functionality to a Python web application using the logging module. A second prompt ensured that sensitive information such as passwords and personal data is excluded from logs. The generated solution follows secure logging practices and protects user privacy."
      ],
      "metadata": {
        "id": "Fe2dMCbyCsjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4"
      ],
      "metadata": {
        "id": "PjEQ-MDU8hWp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "90fa1af4",
        "outputId": "b5c1cc27-ae14-4772-829e-d16dfa73ddb4"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "# 1. Define log file path\n",
        "log_file = 'app.log'\n",
        "\n",
        "# Remove previous log file for clean demonstration\n",
        "if os.path.exists(log_file):\n",
        "    os.remove(log_file)\n",
        "\n",
        "# 2. Configure the root logger\n",
        "# Set the logging level to INFO\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "                    handlers=[\n",
        "                        logging.FileHandler(log_file), # File handler\n",
        "                        logging.StreamHandler() # Console handler\n",
        "                    ])\n",
        "\n",
        "# Get a logger instance\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# 3. Log example messages at different severity levels\n",
        "logger.info('This is an informational message.')\n",
        "logger.warning('This is a warning message, something might be amiss.')\n",
        "logger.error('This is an error message, an issue occurred!')\n",
        "logger.debug('This is a debug message (should not appear as level is INFO).')\n",
        "logger.critical('This is a critical message, immediate attention needed!')\n",
        "\n",
        "print(f\"\\nLogging configured. Check '{log_file}' and console for messages.\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:This is a warning message, something might be amiss.\n",
            "ERROR:__main__:This is an error message, an issue occurred!\n",
            "CRITICAL:__main__:This is a critical message, immediate attention needed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logging configured. Check 'app.log' and console for messages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1de061ff",
        "outputId": "b1449f36-2e4d-48c7-989d-bb4cee20a459"
      },
      "source": [
        "import logging\n",
        "\n",
        "# Re-use the logger configured in the previous step\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def simulate_web_request(method, path, user_agent, ip_address, user_id=None, status_code=200):\n",
        "    \"\"\"\n",
        "    Simulates a web request and logs relevant information.\n",
        "    \"\"\"\n",
        "    if user_id:\n",
        "        logger.info(f\"User {user_id} made a {method} request to {path} from {ip_address} (User-Agent: {user_agent}). Status: {status_code}\")\n",
        "    else:\n",
        "        logger.info(f\"Anonymous user made a {method} request to {path} from {ip_address} (User-Agent: {user_agent}). Status: {status_code}\")\n",
        "\n",
        "def simulate_login_attempt(username, success, ip_address):\n",
        "    \"\"\"\n",
        "    Simulates a login attempt and logs the outcome.\n",
        "    \"\"\"\n",
        "    if success:\n",
        "        logger.info(f\"Successful login for username: {username} from IP: {ip_address}\")\n",
        "    else:\n",
        "        logger.warning(f\"Failed login attempt for username: {username} from IP: {ip_address}\")\n",
        "\n",
        "def simulate_error(error_message, endpoint, user_id=None):\n",
        "    \"\"\"\n",
        "    Simulates an application error.\n",
        "    \"\"\"\n",
        "    if user_id:\n",
        "        logger.error(f\"Application error for user {user_id} at {endpoint}: {error_message}\")\n",
        "    else:\n",
        "        logger.error(f\"Application error at {endpoint}: {error_message}\")\n",
        "\n",
        "print(\"\\n--- Demonstrating Web Context Logging ---\")\n",
        "\n",
        "# Example 1: Successful GET request by a logged-in user\n",
        "simulate_web_request('GET', '/dashboard', 'Mozilla/5.0', '192.168.1.100', user_id='U001')\n",
        "\n",
        "# Example 2: Failed POST request by an anonymous user\n",
        "simulate_web_request('POST', '/login', 'Chrome/100', '203.0.113.50', status_code=401)\n",
        "\n",
        "# Example 3: Successful login\n",
        "simulate_login_attempt('admin_user', True, '192.168.1.100')\n",
        "\n",
        "# Example 4: Failed login (e.g., incorrect password)\n",
        "simulate_login_attempt('invalid_user', False, '203.0.113.51')\n",
        "\n",
        "# Example 5: Application error for a specific user\n",
        "simulate_error('Database connection lost', '/api/data', user_id='U001')\n",
        "\n",
        "# Example 6: General application error\n",
        "simulate_error('Unhandled exception in payment processing', '/checkout')\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Failed login attempt for username: invalid_user from IP: 203.0.113.51\n",
            "ERROR:__main__:Application error for user U001 at /api/data: Database connection lost\n",
            "ERROR:__main__:Application error at /checkout: Unhandled exception in payment processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Web Context Logging ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "93b7f6e1",
        "outputId": "45b9a2ca-5438-41ce-b02a-1d1c068c141c"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Re-use the log file path and ensure it's clean for this demonstration\n",
        "log_file = 'app.log'\n",
        "if os.path.exists(log_file):\n",
        "    os.remove(log_file)\n",
        "\n",
        "class RedactingFormatter(logging.Formatter):\n",
        "    \"\"\"Formatter that redacts sensitive information.\"\"\"\n",
        "    REDACTION_PATTERNS = [\n",
        "        re.compile(r\"(?i)password=['\\\"]?(.*?)(['\\\"]|\\s|$)\"), # Matches 'password=...' or 'password: ...'\n",
        "        re.compile(r\"(?i)api_key=['\\\"]?(.*?)(['\\\"]|\\s|$)\"), # Matches 'api_key=...'\n",
        "        re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"), # Social Security Number (example pattern)\n",
        "        re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\") # Email addresses\n",
        "    ]\n",
        "\n",
        "    def format(self, record):\n",
        "        original_message = super().format(record)\n",
        "        redacted_message = original_message\n",
        "        for pattern in self.REDACTION_PATTERNS:\n",
        "            # Use a lambda function for the replacement to hide the actual match\n",
        "            redacted_message = pattern.sub(lambda m: m.group(0).replace(m.group(1), '********') if m.groups() and m.group(1) else m.group(0), redacted_message)\n",
        "        return redacted_message\n",
        "\n",
        "# Configure a new logger with the redacting formatter\n",
        "# Reset existing handlers to avoid duplicates if cell is re-run\n",
        "root_logger = logging.getLogger()\n",
        "for handler in root_logger.handlers[:]: # Iterate over a copy of the list\n",
        "    root_logger.removeHandler(handler)\n",
        "\n",
        "# Set the logging level to INFO\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers\n",
        "file_handler = logging.FileHandler(log_file)\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "# Create a redacting formatter instance\n",
        "redact_formatter = RedactingFormatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Set formatter for handlers\n",
        "file_handler.setFormatter(redact_formatter)\n",
        "stream_handler.setFormatter(redact_formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "root_logger.addHandler(file_handler)\n",
        "root_logger.addHandler(stream_handler)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\n--- Demonstrating Sensitive Data Redaction ---\")\n",
        "\n",
        "# Example logs with sensitive data\n",
        "logger.info(\"User 'john.doe' attempted login with password='mysecretpassword123'.\")\n",
        "logger.warning(\"New user registered: name='Jane Smith', email='jane.smith@example.com'.\")\n",
        "logger.error(\"Payment failed for transaction ID 12345, API_KEY='sk_test_abcdef12345'.\")\n",
        "logger.info(\"System diagnostic: CPU usage 75%.\")\n",
        "logger.debug(\"This debug message contains no sensitive data.\")\n",
        "logger.critical(\"Security breach detected! User 'evil_hacker' from 192.0.2.1 password='root'\")\n",
        "\n",
        "print(f\"Sensitive data redaction configured. Check '{log_file}' and console for redacted messages.\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-01-29 08:51:47,806 - INFO - User 'john.doe' attempted login with password='********'.\n",
            "2026-01-29 08:51:47,807 - WARNING - New user registered: name='Jane Smith', email='jane.smith@example.com'.\n",
            "2026-01-29 08:51:47,809 - ERROR - Payment failed for transaction ID 12345, API_KEY='********'.\n",
            "2026-01-29 08:51:47,810 - INFO - System diagnostic: CPU usage 75%.\n",
            "2026-01-29 08:51:47,811 - CRITICAL - Security breach detected! User 'evil_hacker' from 192.0.2.1 password='********'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Sensitive Data Redaction ---\n",
            "Sensitive data redaction configured. Check 'app.log' and console for redacted messages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b916e4ba",
        "outputId": "19b79f4c-a914-4f1b-c8c2-84ca22336503"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Re-use the log file path and ensure it's clean for this demonstration\n",
        "log_file = 'app.log'\n",
        "if os.path.exists(log_file):\n",
        "    os.remove(log_file)\n",
        "\n",
        "class RedactingFormatter(logging.Formatter):\n",
        "    \"\"\"Formatter that redacts sensitive information.\"\"\"\n",
        "    REDACTION_PATTERNS = [\n",
        "        # Matches 'password=value', 'api_key:value', etc., whether quoted or not.\n",
        "        # Escaped double quotes \\\" inside the r\"...\" string literal.\n",
        "        re.compile(r\"(?i)(password|passwd|pwd|api_key|secret_key|token)[:=]['\\\"]?[^'\\\"\\s]+['\\\"]?\"),\n",
        "        re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"), # Social Security Number (example pattern)\n",
        "        re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9\\.-]+\\.[A-Za-z]{2,}\\b\") # Email addresses\n",
        "    ]\n",
        "\n",
        "    def format(self, record):\n",
        "        original_message = super().format(record)\n",
        "        redacted_message = original_message\n",
        "        for pattern in self.REDACTION_PATTERNS:\n",
        "            # Replace the entire matched sensitive part with '********'\n",
        "            redacted_message = pattern.sub('********', redacted_message)\n",
        "        return redacted_message\n",
        "\n",
        "# Configure a new logger with the redacting formatter\n",
        "# Reset existing handlers to avoid duplicates if cell is re-run\n",
        "root_logger = logging.getLogger()\n",
        "for handler in root_logger.handlers[:]: # Iterate over a copy of the list\n",
        "    root_logger.removeHandler(handler)\n",
        "\n",
        "# Set the logging level to INFO\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers\n",
        "file_handler = logging.FileHandler(log_file)\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "# Create a redacting formatter instance\n",
        "redact_formatter = RedactingFormatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Set formatter for handlers\n",
        "file_handler.setFormatter(redact_formatter)\n",
        "stream_handler.setFormatter(redact_formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "root_logger.addHandler(file_handler)\n",
        "root_logger.addHandler(stream_handler)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\n--- Demonstrating Sensitive Data Redaction ---\")\n",
        "\n",
        "# Example logs with sensitive data\n",
        "logger.info(\"User 'john.doe' attempted login with password='mysecretpassword123'.\")\n",
        "logger.warning(\"New user registered: name='Jane Smith', email='jane.smith@example.com'.\")\n",
        "logger.error(\"Payment failed for transaction ID 12345, API_KEY='sk_test_abcdef12345'.\")\n",
        "logger.info(\"System diagnostic: CPU usage 75%.\")\n",
        "logger.debug(\"This debug message contains no sensitive data.\")\n",
        "logger.critical(\"Security breach detected! User 'evil_hacker' from 192.0.2.1 password='root'\")\n",
        "logger.info(\"User profile: email=another@example.org, SSN=123-45-6789.\")\n",
        "\n",
        "print(f\"Sensitive data redaction configured. Check '{log_file}' and console for redacted messages.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-01-29 08:52:55,323 - INFO - User 'john.doe' attempted login with ********.\n",
            "2026-01-29 08:52:55,327 - WARNING - New user registered: name='Jane Smith', email='********'.\n",
            "2026-01-29 08:52:55,329 - ERROR - Payment failed for transaction ID 12345, ********.\n",
            "2026-01-29 08:52:55,333 - INFO - System diagnostic: CPU usage 75%.\n",
            "2026-01-29 08:52:55,334 - CRITICAL - Security breach detected! User 'evil_hacker' from 192.0.2.1 ********\n",
            "2026-01-29 08:52:55,338 - INFO - User profile: email=********, SSN=********.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Sensitive Data Redaction ---\n",
            "Sensitive data redaction configured. Check 'app.log' and console for redacted messages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f3861cb7",
        "outputId": "78272280-d104-4050-8a1e-9aba730da745"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Define log file path and ensure it's clean for this demonstration\n",
        "log_file = 'app.log'\n",
        "if os.path.exists(log_file):\n",
        "    os.remove(log_file)\n",
        "\n",
        "class StructuredJsonFormatter(logging.Formatter):\n",
        "    \"\"\"Formatter that outputs logs as JSON and redacts sensitive information.\"\"\"\n",
        "    REDACTION_PATTERNS = [\n",
        "        re.compile(r\"(?i)(password|passwd|pwd|api_key|secret_key|token)[:=]['\\\"]?[^'\\\"\\s]+['\\\"]?\"),\n",
        "        re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"), # Social Security Number (example pattern)\n",
        "        re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9\\.-]+\\.[A-Za-z]{2,}\\b\") # Email addresses\n",
        "    ]\n",
        "\n",
        "    def _redact_value(self, value):\n",
        "        if not isinstance(value, str):\n",
        "            return value\n",
        "        redacted_value = value\n",
        "        for pattern in self.REDACTION_PATTERNS:\n",
        "            redacted_value = pattern.sub('********', redacted_value)\n",
        "        return redacted_value\n",
        "\n",
        "    def format(self, record):\n",
        "        # Create a dictionary from the log record attributes\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.datetime.fromtimestamp(record.created).isoformat(),\n",
        "            \"level\": record.levelname,\n",
        "            \"message\": record.getMessage(),\n",
        "            \"logger_name\": record.name,\n",
        "            \"filename\": record.filename,\n",
        "            \"lineno\": record.lineno,\n",
        "            \"process\": record.process,\n",
        "            \"thread\": record.thread,\n",
        "        }\n",
        "\n",
        "        # Add extra attributes from the log record and redact them\n",
        "        if hasattr(record, '__dict__'):\n",
        "            for key, value in record.__dict__.items():\n",
        "                # Avoid standard attributes already handled or internal attributes\n",
        "                if key not in ['name', 'levelname', 'pathname', 'filename', 'module', 'exc_info', 'exc_text',\n",
        "                               'stack_info', 'lineno', 'created', 'msecs', 'relativeCreated',\n",
        "                               'thread', 'threadName', 'processName', 'process', 'message', 'asctime',\n",
        "                               'args', 'msg', 'levelno', 'extra'] and not key.startswith('_'):\n",
        "                    log_entry[key] = self._redact_value(value)\n",
        "\n",
        "        # Apply redaction to all string values in the log_entry dictionary\n",
        "        for key, value in log_entry.items():\n",
        "            log_entry[key] = self._redact_value(value)\n",
        "\n",
        "        # Serialize the dictionary to a JSON string\n",
        "        return json.dumps(log_entry, default=str)\n",
        "\n",
        "\n",
        "# Configure a new logger with the StructuredJsonFormatter\n",
        "# Reset existing handlers to avoid duplicates if cell is re-run\n",
        "root_logger = logging.getLogger()\n",
        "for handler in root_logger.handlers[:]:\n",
        "    root_logger.removeHandler(handler)\n",
        "\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers\n",
        "file_handler = logging.FileHandler(log_file)\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "# Create a structured JSON formatter instance\n",
        "json_formatter = StructuredJsonFormatter()\n",
        "\n",
        "# Set formatter for handlers\n",
        "file_handler.setFormatter(json_formatter)\n",
        "stream_handler.setFormatter(json_formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "root_logger.addHandler(file_handler)\n",
        "root_logger.addHandler(stream_handler)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\n--- Demonstrating Structured JSON Logging with Redaction ---\")\n",
        "\n",
        "# Example logs with structured data\n",
        "logger.info(\"User activity\", extra={\"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"})\n",
        "logger.warning(\"Configuration error\", extra={\"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3})\n",
        "\n",
        "# Example with sensitive data in message and extra fields, to test redaction within structured logs\n",
        "logger.critical(\n",
        "    \"Security alert: User login failed.\",\n",
        "    extra={\n",
        "        \"user_email\": \"attacker@example.com\",\n",
        "        \"ip_address\": \"192.0.2.10\",\n",
        "        \"password_attempt\": \"weakpass123\",\n",
        "        \"api_key_used\": \"secrettoken123ABC\"\n",
        "    }\n",
        ")\n",
        "logger.info(\"New registration\", extra={\"username\": \"new_user\", \"email\": \"newuser@example.org\", \"registration_ip\": \"10.0.0.5\"})\n",
        "logger.info(\"Payment initiated\", extra={\"transaction_id\": \"TXN789\", \"customer_ssn\": \"987-65-4321\", \"amount\": 199.99})\n",
        "\n",
        "print(f\"Structured JSON logging with redaction configured. Check '{log_file}' and console for logs.\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"timestamp\": \"2026-01-29T08:53:27.169643\", \"level\": \"INFO\", \"message\": \"User activity\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-820964194.py\", \"lineno\": 87, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"}\n",
            "{\"timestamp\": \"2026-01-29T08:53:27.182937\", \"level\": \"WARNING\", \"message\": \"Configuration error\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-820964194.py\", \"lineno\": 88, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3}\n",
            "{\"timestamp\": \"2026-01-29T08:53:27.188978\", \"level\": \"CRITICAL\", \"message\": \"Security alert: User login failed.\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-820964194.py\", \"lineno\": 91, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_email\": \"********\", \"ip_address\": \"192.0.2.10\", \"password_attempt\": \"weakpass123\", \"api_key_used\": \"secrettoken123ABC\"}\n",
            "{\"timestamp\": \"2026-01-29T08:53:27.202545\", \"level\": \"INFO\", \"message\": \"New registration\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-820964194.py\", \"lineno\": 100, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"username\": \"new_user\", \"email\": \"********\", \"registration_ip\": \"10.0.0.5\"}\n",
            "{\"timestamp\": \"2026-01-29T08:53:27.217521\", \"level\": \"INFO\", \"message\": \"Payment initiated\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-820964194.py\", \"lineno\": 101, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"transaction_id\": \"TXN789\", \"customer_ssn\": \"********\", \"amount\": 199.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Structured JSON Logging with Redaction ---\n",
            "Structured JSON logging with redaction configured. Check 'app.log' and console for logs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7cc7ca03",
        "outputId": "1ea751b7-5897-4d29-dac8-de3e1ae47b87"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Define log file path and ensure it's clean for this demonstration\n",
        "log_file = 'app.log'\n",
        "if os.path.exists(log_file):\n",
        "    os.remove(log_file)\n",
        "\n",
        "class StructuredJsonFormatter(logging.Formatter):\n",
        "    \"\"\"Formatter that outputs logs as JSON and redacts sensitive information.\"\"\"\n",
        "    REDACTION_PATTERNS = [\n",
        "        re.compile(r\"(?i)(password|passwd|pwd|api_key|secret_key|token)[:=]['\\\"]?[^'\\\"\\s]+['\\\"]?\"),\n",
        "        re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"), # Social Security Number (example pattern)\n",
        "        re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9\\.-]+\\.[A-Za-z]{2,}\\b\") # Email addresses\n",
        "    ]\n",
        "\n",
        "    def _redact_value(self, value):\n",
        "        if not isinstance(value, str):\n",
        "            return value\n",
        "        redacted_value = value\n",
        "        for pattern in self.REDACTION_PATTERNS:\n",
        "            redacted_value = pattern.sub('********', redacted_value)\n",
        "        return redacted_value\n",
        "\n",
        "    def format(self, record):\n",
        "        # Create a dictionary from the log record attributes\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.datetime.fromtimestamp(record.created).isoformat(),\n",
        "            \"level\": record.levelname,\n",
        "            \"message\": record.getMessage(),\n",
        "            \"logger_name\": record.name,\n",
        "            \"filename\": record.filename,\n",
        "            \"lineno\": record.lineno,\n",
        "            \"process\": record.process,\n",
        "            \"thread\": record.thread,\n",
        "        }\n",
        "\n",
        "        # Add extra attributes from the log record and redact them\n",
        "        if hasattr(record, '__dict__'):\n",
        "            for key, value in record.__dict__.items():\n",
        "                # Avoid standard attributes already handled or internal attributes\n",
        "                if key not in ['name', 'levelname', 'pathname', 'filename', 'module', 'exc_info', 'exc_text',\n",
        "                               'stack_info', 'lineno', 'created', 'msecs', 'relativeCreated',\n",
        "                               'thread', 'threadName', 'processName', 'process', 'message', 'asctime',\n",
        "                               'args', 'msg', 'levelno', 'extra'] and not key.startswith('_'):\n",
        "                    log_entry[key] = self._redact_value(value)\n",
        "\n",
        "        # Apply redaction to all string values in the log_entry dictionary\n",
        "        for key, value in log_entry.items():\n",
        "            log_entry[key] = self._redact_value(value)\n",
        "\n",
        "        # Serialize the dictionary to a JSON string\n",
        "        return json.dumps(log_entry, default=str)\n",
        "\n",
        "\n",
        "# Configure a new logger with the StructuredJsonFormatter\n",
        "# Reset existing handlers to avoid duplicates if cell is re-run\n",
        "root_logger = logging.getLogger()\n",
        "for handler in root_logger.handlers[:]:\n",
        "    root_logger.removeHandler(handler)\n",
        "\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers\n",
        "file_handler = logging.FileHandler(log_file)\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "# Create a structured JSON formatter instance\n",
        "json_formatter = StructuredJsonFormatter()\n",
        "\n",
        "# Set formatter for handlers\n",
        "file_handler.setFormatter(json_formatter)\n",
        "stream_handler.setFormatter(json_formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "root_logger.addHandler(file_handler)\n",
        "root_logger.addHandler(stream_handler)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\n--- Demonstrating Structured JSON Logging with Redaction ---\")\n",
        "\n",
        "# Example logs with structured data\n",
        "logger.info(\"User activity\", extra={\"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"})\n",
        "logger.warning(\"Configuration error\", extra={\"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3})\n",
        "\n",
        "# Example with sensitive data in message and extra fields, to test redaction within structured logs\n",
        "logger.critical(\n",
        "    \"Security alert: User login failed.\",\n",
        "    extra=\n",
        "        {\n",
        "        \"user_email\": \"attacker@example.com\",\n",
        "        \"ip_address\": \"192.0.2.10\",\n",
        "        \"password_attempt\": \"weakpass123\",\n",
        "        \"api_key_used\": \"secrettoken123ABC\"\n",
        "    }\n",
        ")\n",
        "logger.info(\"New registration\", extra={\"username\": \"new_user\", \"email\": \"newuser@example.org\", \"registration_ip\": \"10.0.0.5\"})\n",
        "logger.info(\"Payment initiated\", extra={\"transaction_id\": \"TXN789\", \"customer_ssn\": \"987-65-4321\", \"amount\": 199.99})\n",
        "\n",
        "print(f\"Structured JSON logging with redaction configured. Check '{log_file}' and console for logs.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"timestamp\": \"2026-01-29T08:53:41.128978\", \"level\": \"INFO\", \"message\": \"User activity\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2177444732.py\", \"lineno\": 87, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"}\n",
            "{\"timestamp\": \"2026-01-29T08:53:41.134618\", \"level\": \"WARNING\", \"message\": \"Configuration error\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2177444732.py\", \"lineno\": 88, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3}\n",
            "{\"timestamp\": \"2026-01-29T08:53:41.140724\", \"level\": \"CRITICAL\", \"message\": \"Security alert: User login failed.\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2177444732.py\", \"lineno\": 91, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_email\": \"********\", \"ip_address\": \"192.0.2.10\", \"password_attempt\": \"weakpass123\", \"api_key_used\": \"secrettoken123ABC\"}\n",
            "{\"timestamp\": \"2026-01-29T08:53:41.145387\", \"level\": \"INFO\", \"message\": \"New registration\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2177444732.py\", \"lineno\": 101, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"username\": \"new_user\", \"email\": \"********\", \"registration_ip\": \"10.0.0.5\"}\n",
            "{\"timestamp\": \"2026-01-29T08:53:41.151498\", \"level\": \"INFO\", \"message\": \"Payment initiated\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2177444732.py\", \"lineno\": 102, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"transaction_id\": \"TXN789\", \"customer_ssn\": \"********\", \"amount\": 199.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Structured JSON Logging with Redaction ---\n",
            "Structured JSON logging with redaction configured. Check 'app.log' and console for logs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6eff5ced",
        "outputId": "46333cd2-0d27-4ef7-e02e-fdd456fb4ae0"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Define log file path and ensure it's clean for this demonstration\n",
        "log_file = 'app.log'\n",
        "if os.path.exists(log_file):\n",
        "    os.remove(log_file)\n",
        "\n",
        "class StructuredJsonFormatter(logging.Formatter):\n",
        "    \"\"\"Formatter that outputs logs as JSON and redacts sensitive information.\"\"\"\n",
        "    REDACTION_PATTERNS = [\n",
        "        # Changed raw string delimiter to single quotes to allow unescaped double quotes inside.\n",
        "        re.compile(r'(?i)(password|passwd|pwd|api_key|secret_key|token)[:=][\"\\\\]?[^\"\\\\s]+[\"\\\\]?'),\n",
        "        re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"), # Social Security Number (example pattern)\n",
        "        re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9\\.-]+\\.[A-Za-z]{2,}\\b\") # Email addresses\n",
        "    ]\n",
        "\n",
        "    def _redact_value(self, value):\n",
        "        if isinstance(value, str):\n",
        "            redacted_value = value\n",
        "            for pattern in self.REDACTION_PATTERNS:\n",
        "                redacted_value = pattern.sub('********', redacted_value)\n",
        "            return redacted_value\n",
        "        elif isinstance(value, dict):\n",
        "            return {k: self._redact_value(v) for k, v in value.items()}\n",
        "        elif isinstance(value, list):\n",
        "            return [self._redact_value(item) for item in value]\n",
        "        else:\n",
        "            return value\n",
        "\n",
        "    def format(self, record):\n",
        "        # Create a dictionary from the log record attributes\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.datetime.fromtimestamp(record.created).isoformat(),\n",
        "            \"level\": record.levelname,\n",
        "            \"message\": record.getMessage(),\n",
        "            \"logger_name\": record.name,\n",
        "            \"filename\": record.filename,\n",
        "            \"lineno\": record.lineno,\n",
        "            \"process\": record.process,\n",
        "            \"thread\": record.thread,\n",
        "            \"funcName\": getattr(record, 'funcName', None),\n",
        "            \"taskName\": getattr(record, 'taskName', None) # Read taskName if it exists\n",
        "        }\n",
        "\n",
        "        # Redact the main message as well\n",
        "        log_entry[\"message\"] = self._redact_value(log_entry[\"message\"])\n",
        "\n",
        "        # Define a set of standard LogRecord attributes to avoid duplication\n",
        "        STANDARD_LOG_RECORD_ATTRIBUTES = {\n",
        "            'name', 'levelname', 'levelno', 'pathname', 'filename', 'module', 'lineno',\n",
        "            'funcName', 'created', 'asctime', 'msecs', 'relativeCreated', 'thread',\n",
        "            'threadName', 'process', 'processName', 'message', 'args', 'exc_info',\n",
        "            'exc_text', 'stack_info', 'msg',\n",
        "            'extra' # if the 'extra' dict itself is somehow present as an attribute\n",
        "        }\n",
        "\n",
        "        # Add any other attributes that were passed via 'extra' or added dynamically\n",
        "        for key, value in record.__dict__.items():\n",
        "            if not key.startswith('_') and key not in log_entry and key not in STANDARD_LOG_RECORD_ATTRIBUTES:\n",
        "                log_entry[key] = self._redact_value(value)\n",
        "\n",
        "        # Serialize the dictionary to a JSON string\n",
        "        return json.dumps(log_entry, default=str)\n",
        "\n",
        "\n",
        "# Configure a new logger with the StructuredJsonFormatter\n",
        "# Reset existing handlers to avoid duplicates if cell is re-run\n",
        "root_logger = logging.getLogger()\n",
        "for handler in root_logger.handlers[:]:\n",
        "    root_logger.removeHandler(handler)\n",
        "\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers\n",
        "file_handler = logging.FileHandler(log_file)\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "# Create a structured JSON formatter instance\n",
        "json_formatter = StructuredJsonFormatter()\n",
        "\n",
        "# Set formatter for handlers\n",
        "file_handler.setFormatter(json_formatter)\n",
        "stream_handler.setFormatter(json_formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "root_logger.addHandler(file_handler)\n",
        "root_logger.addHandler(stream_handler)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\n--- Demonstrating Structured JSON Logging with Recursive Redaction ---\")\n",
        "\n",
        "# Example logs with structured data, including nested sensitive data\n",
        "# Removed 'taskName' from extra dicts to avoid KeyError as it's likely set by environment\n",
        "logger.info(\"User activity\", extra={\"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"})\n",
        "logger.warning(\"Configuration error\", extra={\"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3})\n",
        "\n",
        "# Example with sensitive data in message and extra fields, to test redaction within structured logs\n",
        "logger.critical(\n",
        "    \"Security alert: User login failed. password_attempt=weakpass123\",\n",
        "    extra={\n",
        "        \"user_email\": \"attacker@example.com\",\n",
        "        \"ip_address\": \"192.0.2.10\",\n",
        "        \"auth_details\": {\n",
        "            \"username\": \"badactor\",\n",
        "            \"password\": \"anotherbadpassword\",\n",
        "            \"api_key\": \"nested_secret_key_123\"\n",
        "        },\n",
        "        \"attempts\": [\n",
        "            {\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"oldpass@domain.com\"},\n",
        "            {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"badpassword\"}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "logger.info(\"New registration\", extra={\"username\": \"new_user\", \"email\": \"newuser@example.org\", \"registration_ip\": \"10.0.0.5\"})\n",
        "logger.info(\"Payment initiated\", extra={\"transaction_id\": \"TXN789\", \"customer_ssn\": \"987-65-4321\", \"amount\": 199.99})\n",
        "\n",
        "print(f\"Structured JSON logging with recursive redaction configured. Check '{log_file}' and console for logs.\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"timestamp\": \"2026-01-29T08:55:55.843502\", \"level\": \"INFO\", \"message\": \"User activity\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-254711033.py\", \"lineno\": 99, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"}\n",
            "{\"timestamp\": \"2026-01-29T08:55:55.848739\", \"level\": \"WARNING\", \"message\": \"Configuration error\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-254711033.py\", \"lineno\": 100, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3}\n",
            "{\"timestamp\": \"2026-01-29T08:55:55.851416\", \"level\": \"CRITICAL\", \"message\": \"Security alert: User login failed. password_attempt=weakpass123\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-254711033.py\", \"lineno\": 103, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_email\": \"********\", \"ip_address\": \"192.0.2.10\", \"auth_details\": {\"username\": \"badactor\", \"password\": \"anotherbadpassword\", \"api_key\": \"nested_secret_key_123\"}, \"attempts\": [{\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"********\"}, {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"badpassword\"}]}\n",
            "{\"timestamp\": \"2026-01-29T08:55:55.853219\", \"level\": \"INFO\", \"message\": \"New registration\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-254711033.py\", \"lineno\": 119, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"username\": \"new_user\", \"email\": \"********\", \"registration_ip\": \"10.0.0.5\"}\n",
            "{\"timestamp\": \"2026-01-29T08:55:55.854725\", \"level\": \"INFO\", \"message\": \"Payment initiated\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-254711033.py\", \"lineno\": 120, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"transaction_id\": \"TXN789\", \"customer_ssn\": \"********\", \"amount\": 199.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Structured JSON Logging with Recursive Redaction ---\n",
            "Structured JSON logging with recursive redaction configured. Check 'app.log' and console for logs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6b69e246",
        "outputId": "51935628-0379-4780-9ed3-91d85ecca5a3"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Define log file path and ensure it's clean for this demonstration\n",
        "log_file = 'app.log'\n",
        "if os.path.exists(log_file):\n",
        "    os.remove(log_file)\n",
        "\n",
        "class StructuredJsonFormatter(logging.Formatter):\n",
        "    \"\"\"Formatter that outputs logs as JSON and redacts sensitive information.\"\"\"\n",
        "    SENSITIVE_KEYS = {\n",
        "        'password', 'passwd', 'pwd', 'api_key', 'secret_key', 'token',\n",
        "        'user_email', 'email', 'credential', 'ssn', 'customer_ssn', 'password_attempt'\n",
        "    }\n",
        "\n",
        "    REDACTION_PATTERNS = [\n",
        "        re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"), # Social Security Number (example pattern)\n",
        "        re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9\\.-]+\\.[A-Za-z]{2,}\\b\"), # Email addresses\n",
        "        # Pattern for sensitive key=value or key:value pairs embedded in a plain string message\n",
        "        # Uses non-capturing group (?:...) for keys and correctly handles optional quotes around values.\n",
        "        re.compile(r'(?i)\\b(?:password|passwd|pwd|api_key|secret_key|token|credential|ssn|customer_ssn|password_attempt)[:=][\\'\"]?[^\\'\"\\s]+[\\'\"]?\\b')\n",
        "    ]\n",
        "\n",
        "    def _redact_value(self, value, key_context=None):\n",
        "        # If the current item is the value of a sensitive key, redact it directly\n",
        "        if isinstance(key_context, str) and key_context.lower() in self.SENSITIVE_KEYS:\n",
        "            return '********'\n",
        "\n",
        "        if isinstance(value, str):\n",
        "            redacted_value = value\n",
        "            for pattern in self.REDACTION_PATTERNS:\n",
        "                redacted_value = pattern.sub('********', redacted_value)\n",
        "            return redacted_value\n",
        "        elif isinstance(value, dict):\n",
        "            # Recursively redact values in a dictionary, passing the key as context\n",
        "            return {k: self._redact_value(v, k) for k, v in value.items()}\n",
        "        elif isinstance(value, list):\n",
        "            # Recursively redact elements in a list (no key_context for list items themselves)\n",
        "            return [self._redact_value(item, None) for item in value]\n",
        "        else:\n",
        "            return value\n",
        "\n",
        "    def format(self, record):\n",
        "        # Create a dictionary from the log record attributes\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.datetime.fromtimestamp(record.created).isoformat(),\n",
        "            \"level\": record.levelname,\n",
        "            \"message\": self._redact_value(record.getMessage()), # Redact the main message\n",
        "            \"logger_name\": record.name,\n",
        "            \"filename\": record.filename,\n",
        "            \"lineno\": record.lineno,\n",
        "            \"process\": record.process,\n",
        "            \"thread\": record.thread,\n",
        "            \"funcName\": getattr(record, 'funcName', None),\n",
        "            \"taskName\": getattr(record, 'taskName', None) # Read taskName if it exists\n",
        "        }\n",
        "\n",
        "        # Define a set of standard LogRecord attributes to avoid duplication\n",
        "        STANDARD_LOG_RECORD_ATTRIBUTES = {\n",
        "            'name', 'levelname', 'levelno', 'pathname', 'filename', 'module', 'lineno',\n",
        "            'funcName', 'created', 'asctime', 'msecs', 'relativeCreated', 'thread',\n",
        "            'threadName', 'process', 'processName', 'message', 'args', 'exc_info',\n",
        "            'exc_text', 'stack_info', 'msg',\n",
        "            'extra' # if the 'extra' dict itself is somehow present as an attribute\n",
        "        }\n",
        "\n",
        "        # Add extra attributes from the log record and recursively redact them, passing the key as context\n",
        "        for key, value in record.__dict__.items():\n",
        "            if not key.startswith('_') and key not in log_entry and key not in STANDARD_LOG_RECORD_ATTRIBUTES:\n",
        "                log_entry[key] = self._redact_value(value, key)\n",
        "\n",
        "        # Serialize the dictionary to a JSON string\n",
        "        return json.dumps(log_entry, default=str)\n",
        "\n",
        "\n",
        "# Configure a new logger with the StructuredJsonFormatter\n",
        "# Reset existing handlers to avoid duplicates if cell is re-run\n",
        "root_logger = logging.getLogger()\n",
        "for handler in root_logger.handlers[:]:\n",
        "    root_logger.removeHandler(handler)\n",
        "\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers\n",
        "file_handler = logging.FileHandler(log_file)\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "# Create a structured JSON formatter instance\n",
        "json_formatter = StructuredJsonFormatter()\n",
        "\n",
        "# Set formatter for handlers\n",
        "file_handler.setFormatter(json_formatter)\n",
        "stream_handler.setFormatter(json_formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "root_logger.addHandler(file_handler)\n",
        "root_logger.addHandler(stream_handler)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\n--- Demonstrating Structured JSON Logging with Recursive Redaction ---\")\n",
        "\n",
        "# Example logs with structured data, including nested sensitive data\n",
        "# Removed 'taskName' from extra dicts to avoid KeyError as it's likely set by environment\n",
        "logger.info(\"User activity\", extra={\"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"})\n",
        "logger.warning(\"Configuration error\", extra={\"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3})\n",
        "\n",
        "# Example with sensitive data in message and extra fields, to test redaction within structured logs\n",
        "logger.critical(\n",
        "    \"Security alert: User login failed. password_attempt=weakpass123\",\n",
        "    extra={\n",
        "        \"user_email\": \"attacker@example.com\",\n",
        "        \"ip_address\": \"192.0.2.10\",\n",
        "        \"auth_details\": {\n",
        "            \"username\": \"badactor\",\n",
        "            \"password\": \"anotherbadpassword\",\n",
        "            \"api_key\": \"nested_secret_key_123\"\n",
        "        },\n",
        "        \"attempts\": [\n",
        "            {\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"oldpass@domain.com\"},\n",
        "            {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"badpassword\"}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "logger.info(\"New registration\", extra={\"username\": \"new_user\", \"email\": \"newuser@example.org\", \"registration_ip\": \"10.0.0.5\"})\n",
        "logger.info(\"Payment initiated\", extra={\"transaction_id\": \"TXN789\", \"customer_ssn\": \"987-65-4321\", \"amount\": 199.99})\n",
        "\n",
        "print(f\"Structured JSON logging with recursive redaction configured. Check '{log_file}' and console for logs.\")\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"timestamp\": \"2026-01-29T08:56:48.504701\", \"level\": \"INFO\", \"message\": \"User activity\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-4092724589.py\", \"lineno\": 108, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"}\n",
            "{\"timestamp\": \"2026-01-29T08:56:48.506647\", \"level\": \"WARNING\", \"message\": \"Configuration error\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-4092724589.py\", \"lineno\": 109, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3}\n",
            "{\"timestamp\": \"2026-01-29T08:56:48.510462\", \"level\": \"CRITICAL\", \"message\": \"Security alert: User login failed. ********\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-4092724589.py\", \"lineno\": 112, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_email\": \"********\", \"ip_address\": \"192.0.2.10\", \"auth_details\": {\"username\": \"badactor\", \"password\": \"********\", \"api_key\": \"********\"}, \"attempts\": [{\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"********\"}, {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"********\"}]}\n",
            "{\"timestamp\": \"2026-01-29T08:56:48.511691\", \"level\": \"INFO\", \"message\": \"New registration\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-4092724589.py\", \"lineno\": 128, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"username\": \"new_user\", \"email\": \"********\", \"registration_ip\": \"10.0.0.5\"}\n",
            "{\"timestamp\": \"2026-01-29T08:56:48.515317\", \"level\": \"INFO\", \"message\": \"Payment initiated\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-4092724589.py\", \"lineno\": 129, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"transaction_id\": \"TXN789\", \"customer_ssn\": \"********\", \"amount\": 199.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Structured JSON Logging with Recursive Redaction ---\n",
            "Structured JSON logging with recursive redaction configured. Check 'app.log' and console for logs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8874a652",
        "outputId": "7513d642-ef05-4406-9fba-2ab40bcc0cdc"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "import datetime\n",
        "from logging.handlers import TimedRotatingFileHandler # Import for log rotation\n",
        "\n",
        "# Define log file path and ensure it's clean for this demonstration\n",
        "log_file = 'app.log'\n",
        "\n",
        "# Clean up existing log files and any rotated backups for a fresh start\n",
        "for f in os.listdir('.'):\n",
        "    if f.startswith('app.log') or f.startswith('app.log.'):\n",
        "        os.remove(f)\n",
        "\n",
        "class StructuredJsonFormatter(logging.Formatter):\n",
        "    \"\"\"Formatter that outputs logs as JSON and redacts sensitive information.\"\"\"\n",
        "    SENSITIVE_KEYS = {\n",
        "        'password', 'passwd', 'pwd', 'api_key', 'secret_key', 'token',\n",
        "        'user_email', 'email', 'credential', 'ssn', 'customer_ssn', 'password_attempt'\n",
        "    }\n",
        "\n",
        "    REDACTION_PATTERNS = [\n",
        "        re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"), # Social Security Number (example pattern)\n",
        "        re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9\\.-]+\\.[A-Za-z]{2,}\\b\"), # Email addresses\n",
        "        # Pattern for sensitive key=value or key:value pairs embedded in a plain string message\n",
        "        # Uses non-capturing group (?:...) for keys and correctly handles optional quotes around values.\n",
        "        re.compile(r'(?i)\\b(?:password|passwd|pwd|api_key|secret_key|token|credential|ssn|customer_ssn|password_attempt)[:=][\\'\\\"]?[^\\'\\\"\\s]+[\\'\\\"]?\\b')\n",
        "    ]\n",
        "\n",
        "    def _redact_value(self, value, key_context=None):\n",
        "        # If the current item is the value of a sensitive key, redact it directly\n",
        "        if isinstance(key_context, str) and key_context.lower() in self.SENSITIVE_KEYS:\n",
        "            return '********'\n",
        "\n",
        "        if isinstance(value, str):\n",
        "            redacted_value = value\n",
        "            for pattern in self.REDACTION_PATTERNS:\n",
        "                redacted_value = pattern.sub('********', redacted_value)\n",
        "            return redacted_value\n",
        "        elif isinstance(value, dict):\n",
        "            # Recursively redact values in a dictionary, passing the key as context\n",
        "            return {k: self._redact_value(v, k) for k, v in value.items()}\n",
        "        elif isinstance(value, list):\n",
        "            # Recursively redact elements in a list (no key_context for list items themselves)\n",
        "            return [self._redact_value(item, None) for item in value]\n",
        "        else:\n",
        "            return value\n",
        "\n",
        "    def format(self, record):\n",
        "        # Create a dictionary from the log record attributes\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.datetime.fromtimestamp(record.created).isoformat(),\n",
        "            \"level\": record.levelname,\n",
        "            \"message\": self._redact_value(record.getMessage()), # Redact the main message\n",
        "            \"logger_name\": record.name,\n",
        "            \"filename\": record.filename,\n",
        "            \"lineno\": record.lineno,\n",
        "            \"process\": record.process,\n",
        "            \"thread\": record.thread,\n",
        "            \"funcName\": getattr(record, 'funcName', None),\n",
        "            \"taskName\": getattr(record, 'taskName', None) # Read taskName if it exists\n",
        "        }\n",
        "\n",
        "        # Define a set of standard LogRecord attributes to avoid duplication\n",
        "        STANDARD_LOG_RECORD_ATTRIBUTES = {\n",
        "            'name', 'levelname', 'levelno', 'pathname', 'filename', 'module', 'lineno',\n",
        "            'funcName', 'created', 'asctime', 'msecs', 'relativeCreated', 'thread',\n",
        "            'threadName', 'process', 'processName', 'message', 'args', 'exc_info',\n",
        "            'exc_text', 'stack_info', 'msg',\n",
        "            'extra' # if the 'extra' dict itself is somehow present as an attribute\n",
        "        }\n",
        "\n",
        "        # Add extra attributes from the log record and recursively redact them, passing the key as context\n",
        "        for key, value in record.__dict__.items():\n",
        "            if not key.startswith('_') and key not in log_entry and key not in STANDARD_LOG_RECORD_ATTRIBUTES:\n",
        "                log_entry[key] = self._redact_value(value, key)\n",
        "\n",
        "        # Serialize the dictionary to a JSON string\n",
        "        return json.dumps(log_entry, default=str)\n",
        "\n",
        "\n",
        "# Configure a new logger with the StructuredJsonFormatter and TimedRotatingFileHandler\n",
        "# Reset existing handlers to avoid duplicates if cell is re-run\n",
        "root_logger = logging.getLogger()\n",
        "for handler in root_logger.handlers[:]:\n",
        "    root_logger.removeHandler(handler)\n",
        "\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers\n",
        "# 1. Console Handler (StreamHandler)\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "# 2. Timed Rotating File Handler for log retention\n",
        "# Rotates every minute, keeps 5 backup files (for demonstration purposes)\n",
        "# In a real application, 'when' could be 'midnight' or 'H' (hourly) with larger intervals.\n",
        "file_handler = TimedRotatingFileHandler(log_file, when='M', interval=1, backupCount=5)\n",
        "\n",
        "# Create a structured JSON formatter instance\n",
        "json_formatter = StructuredJsonFormatter()\n",
        "\n",
        "# Set formatter for handlers\n",
        "file_handler.setFormatter(json_formatter)\n",
        "stream_handler.setFormatter(json_formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "root_logger.addHandler(file_handler)\n",
        "root_logger.addHandler(stream_handler)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\n--- Demonstrating Structured JSON Logging with Recursive Redaction and Log Rotation ---\")\n",
        "print(f\"Logs will be written to '{log_file}' and rotated (keeping 5 backups) every minute.\")\n",
        "\n",
        "# Example logs with structured data, including nested sensitive data\n",
        "logger.info(\"User activity\", extra={\"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"})\n",
        "logger.warning(\"Configuration error\", extra={\"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3})\n",
        "\n",
        "# Example with sensitive data in message and extra fields, to test redaction within structured logs\n",
        "logger.critical(\n",
        "    \"Security alert: User login failed. password_attempt=weakpass123\",\n",
        "    extra={\n",
        "        \"user_email\": \"attacker@example.com\",\n",
        "        \"ip_address\": \"192.0.2.10\",\n",
        "        \"auth_details\": {\n",
        "            \"username\": \"badactor\",\n",
        "            \"password\": \"anotherbadpassword\",\n",
        "            \"api_key\": \"nested_secret_key_123\"\n",
        "        },\n",
        "        \"attempts\": [\n",
        "            {\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"oldpass@domain.com\"},\n",
        "            {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"badpassword\"}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "logger.info(\"New registration\", extra={\"username\": \"new_user\", \"email\": \"newuser@example.org\", \"registration_ip\": \"10.0.0.5\"})\n",
        "logger.info(\"Payment initiated\", extra={\"transaction_id\": \"TXN789\", \"customer_ssn\": \"987-65-4321\", \"amount\": 199.99})\n",
        "\n",
        "print(f\"Structured JSON logging with recursive redaction and rotation configured. Check '{log_file}' and console for logs.\")\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"timestamp\": \"2026-01-29T08:57:08.230474\", \"level\": \"INFO\", \"message\": \"User activity\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 117, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"}\n",
            "{\"timestamp\": \"2026-01-29T08:57:08.234511\", \"level\": \"WARNING\", \"message\": \"Configuration error\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 118, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3}\n",
            "{\"timestamp\": \"2026-01-29T08:57:08.238523\", \"level\": \"CRITICAL\", \"message\": \"Security alert: User login failed. ********\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 121, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_email\": \"********\", \"ip_address\": \"192.0.2.10\", \"auth_details\": {\"username\": \"badactor\", \"password\": \"********\", \"api_key\": \"********\"}, \"attempts\": [{\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"********\"}, {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"********\"}]}\n",
            "{\"timestamp\": \"2026-01-29T08:57:08.242712\", \"level\": \"INFO\", \"message\": \"New registration\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 137, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"username\": \"new_user\", \"email\": \"********\", \"registration_ip\": \"10.0.0.5\"}\n",
            "{\"timestamp\": \"2026-01-29T08:57:08.244383\", \"level\": \"INFO\", \"message\": \"Payment initiated\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 138, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"transaction_id\": \"TXN789\", \"customer_ssn\": \"********\", \"amount\": 199.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Structured JSON Logging with Recursive Redaction and Log Rotation ---\n",
            "Logs will be written to 'app.log' and rotated (keeping 5 backups) every minute.\n",
            "Structured JSON logging with recursive redaction and rotation configured. Check 'app.log' and console for logs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "56b78fd0",
        "outputId": "e1420088-b68f-424c-90db-926022985032"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "import datetime\n",
        "from logging.handlers import TimedRotatingFileHandler # Import for log rotation\n",
        "\n",
        "# Define log file path and ensure it's clean for this demonstration\n",
        "log_file = 'app.log'\n",
        "\n",
        "# Clean up existing log files and any rotated backups for a fresh start\n",
        "for f in os.listdir('.'):\n",
        "    if f.startswith('app.log') or f.startswith('app.log.'):\n",
        "        os.remove(f)\n",
        "\n",
        "class StructuredJsonFormatter(logging.Formatter):\n",
        "    \"\"\"Formatter that outputs logs as JSON and redacts sensitive information.\"\"\"\n",
        "    SENSITIVE_KEYS = {\n",
        "        'password', 'passwd', 'pwd', 'api_key', 'secret_key', 'token',\n",
        "        'user_email', 'email', 'credential', 'ssn', 'customer_ssn', 'password_attempt'\n",
        "    }\n",
        "\n",
        "    REDACTION_PATTERNS = [\n",
        "        re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"), # Social Security Number (example pattern)\n",
        "        re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9\\.-]+\\.[A-Za-z]{2,}\\b\"), # Email addresses\n",
        "        # Pattern for sensitive key=value or key:value pairs embedded in a plain string message\n",
        "        # Uses non-capturing group (?:...) for keys and correctly handles optional quotes around values.\n",
        "        re.compile(r'(?i)\\b(?:password|passwd|pwd|api_key|secret_key|token|credential|ssn|customer_ssn|password_attempt)[:=][\\'\\\"]?[^\\'\\\"\\s]+[\\'\\\"]?\\b')\n",
        "    ]\n",
        "\n",
        "    def _redact_value(self, value, key_context=None):\n",
        "        # If the current item is the value of a sensitive key, redact it directly\n",
        "        if isinstance(key_context, str) and key_context.lower() in self.SENSITIVE_KEYS:\n",
        "            return '********'\n",
        "\n",
        "        if isinstance(value, str):\n",
        "            redacted_value = value\n",
        "            for pattern in self.REDACTION_PATTERNS:\n",
        "                redacted_value = pattern.sub('********', redacted_value)\n",
        "            return redacted_value\n",
        "        elif isinstance(value, dict):\n",
        "            # Recursively redact values in a dictionary, passing the key as context\n",
        "            return {k: self._redact_value(v, k) for k, v in value.items()}\n",
        "        elif isinstance(value, list):\n",
        "            # Recursively redact elements in a list (no key_context for list items themselves)\n",
        "            return [self._redact_value(item, None) for item in value]\n",
        "        else:\n",
        "            return value\n",
        "\n",
        "    def format(self, record):\n",
        "        # Create a dictionary from the log record attributes\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.datetime.fromtimestamp(record.created).isoformat(),\n",
        "            \"level\": record.levelname,\n",
        "            \"message\": self._redact_value(record.getMessage()), # Redact the main message\n",
        "            \"logger_name\": record.name,\n",
        "            \"filename\": record.filename,\n",
        "            \"lineno\": record.lineno,\n",
        "            \"process\": record.process,\n",
        "            \"thread\": record.thread,\n",
        "            \"funcName\": getattr(record, 'funcName', None),\n",
        "            \"taskName\": getattr(record, 'taskName', None) # Read taskName if it exists\n",
        "        }\n",
        "\n",
        "        # Define a set of standard LogRecord attributes to avoid duplication\n",
        "        STANDARD_LOG_RECORD_ATTRIBUTES = {\n",
        "            'name', 'levelname', 'levelno', 'pathname', 'filename', 'module', 'lineno',\n",
        "            'funcName', 'created', 'asctime', 'msecs', 'relativeCreated', 'thread',\n",
        "            'threadName', 'process', 'processName', 'message', 'args', 'exc_info',\n",
        "            'exc_text', 'stack_info', 'msg',\n",
        "            'extra' # if the 'extra' dict itself is somehow present as an attribute\n",
        "        }\n",
        "\n",
        "        # Add extra attributes from the log record and recursively redact them, passing the key as context\n",
        "        for key, value in record.__dict__.items():\n",
        "            if not key.startswith('_') and key not in log_entry and key not in STANDARD_LOG_RECORD_ATTRIBUTES:\n",
        "                log_entry[key] = self._redact_value(value, key)\n",
        "\n",
        "        # Serialize the dictionary to a JSON string\n",
        "        return json.dumps(log_entry, default=str)\n",
        "\n",
        "\n",
        "# Configure a new logger with the StructuredJsonFormatter and TimedRotatingFileHandler\n",
        "# Reset existing handlers to avoid duplicates if cell is re-run\n",
        "root_logger = logging.getLogger()\n",
        "for handler in root_logger.handlers[:]:\n",
        "    root_logger.removeHandler(handler)\n",
        "\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers\n",
        "# 1. Console Handler (StreamHandler)\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "# 2. Timed Rotating File Handler for log retention\n",
        "# Rotates every minute, keeps 5 backup files (for demonstration purposes)\n",
        "# In a real application, 'when' could be 'midnight' or 'H' (hourly) with larger intervals.\n",
        "file_handler = TimedRotatingFileHandler(log_file, when='M', interval=1, backupCount=5)\n",
        "\n",
        "# Create a structured JSON formatter instance\n",
        "json_formatter = StructuredJsonFormatter()\n",
        "\n",
        "# Set formatter for handlers\n",
        "file_handler.setFormatter(json_formatter)\n",
        "stream_handler.setFormatter(json_formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "root_logger.addHandler(file_handler)\n",
        "root_logger.addHandler(stream_handler)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\n--- Demonstrating Structured JSON Logging with Recursive Redaction and Log Rotation ---\")\n",
        "print(f\"Logs will be written to '{log_file}' and rotated (keeping 5 backups) every minute.\")\n",
        "\n",
        "# Example logs with structured data, including nested sensitive data\n",
        "logger.info(\"User activity\", extra={\"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"})\n",
        "logger.warning(\"Configuration error\", extra={\"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3})\n",
        "\n",
        "# Example with sensitive data in message and extra fields, to test redaction within structured logs\n",
        "logger.critical(\n",
        "    \"Security alert: User login failed. password_attempt=weakpass123\",\n",
        "    extra={\n",
        "        \"user_email\": \"attacker@example.com\",\n",
        "        \"ip_address\": \"192.0.2.10\",\n",
        "        \"auth_details\": {\n",
        "            \"username\": \"badactor\",\n",
        "            \"password\": \"anotherbadpassword\",\n",
        "            \"api_key\": \"nested_secret_key_123\"\n",
        "        },\n",
        "        \"attempts\": [\n",
        "            {\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"oldpass@domain.com\"},\n",
        "            {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"badpassword\"}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "logger.info(\"New registration\", extra={\"username\": \"new_user\", \"email\": \"newuser@example.org\", \"registration_ip\": \"10.0.0.5\"})\n",
        "logger.info(\"Payment initiated\", extra={\"transaction_id\": \"TXN789\", \"customer_ssn\": \"987-65-4321\", \"amount\": 199.99})\n",
        "\n",
        "print(f\"Structured JSON logging with recursive redaction and rotation configured. Check '{log_file}' and console for logs.\")\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"timestamp\": \"2026-01-29T08:57:26.001678\", \"level\": \"INFO\", \"message\": \"User activity\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 117, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"}\n",
            "{\"timestamp\": \"2026-01-29T08:57:26.003961\", \"level\": \"WARNING\", \"message\": \"Configuration error\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 118, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3}\n",
            "{\"timestamp\": \"2026-01-29T08:57:26.006651\", \"level\": \"CRITICAL\", \"message\": \"Security alert: User login failed. ********\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 121, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_email\": \"********\", \"ip_address\": \"192.0.2.10\", \"auth_details\": {\"username\": \"badactor\", \"password\": \"********\", \"api_key\": \"********\"}, \"attempts\": [{\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"********\"}, {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"********\"}]}\n",
            "{\"timestamp\": \"2026-01-29T08:57:26.009377\", \"level\": \"INFO\", \"message\": \"New registration\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 137, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"username\": \"new_user\", \"email\": \"********\", \"registration_ip\": \"10.0.0.5\"}\n",
            "{\"timestamp\": \"2026-01-29T08:57:26.011559\", \"level\": \"INFO\", \"message\": \"Payment initiated\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-2629836895.py\", \"lineno\": 138, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"transaction_id\": \"TXN789\", \"customer_ssn\": \"********\", \"amount\": 199.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Structured JSON Logging with Recursive Redaction and Log Rotation ---\n",
            "Logs will be written to 'app.log' and rotated (keeping 5 backups) every minute.\n",
            "Structured JSON logging with recursive redaction and rotation configured. Check 'app.log' and console for logs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "150364a0",
        "outputId": "0d29a45f-e7a4-46b8-e142-5914b8a6a89c"
      },
      "source": [
        "import logging\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "import datetime\n",
        "from logging.handlers import TimedRotatingFileHandler # Import for log rotation\n",
        "\n",
        "# Define log file path and ensure it's clean for this demonstration\n",
        "log_file = 'app.log'\n",
        "\n",
        "# Clean up existing log files and any rotated backups for a fresh start\n",
        "for f in os.listdir('.'):\n",
        "    if f.startswith('app.log') or f.startswith('app.log.'):\n",
        "        os.remove(f)\n",
        "\n",
        "class StructuredJsonFormatter(logging.Formatter):\n",
        "    \"\"\"Formatter that outputs logs as JSON and redacts sensitive information.\"\"\"\n",
        "    SENSITIVE_KEYS = {\n",
        "        'password', 'passwd', 'pwd', 'api_key', 'secret_key', 'token',\n",
        "        'user_email', 'email', 'credential', 'ssn', 'customer_ssn', 'password_attempt'\n",
        "    }\n",
        "\n",
        "    REDACTION_PATTERNS = [\n",
        "        re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"), # Social Security Number (example pattern)\n",
        "        re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9\\.-]+\\.[A-Za-z]{2,}\\b\"), # Email addresses\n",
        "        # Pattern for sensitive key=value or key:value pairs embedded in a plain string message\n",
        "        # Uses non-capturing group (?:...) for keys and correctly handles optional quotes around values.\n",
        "        re.compile(r'(?i)\\b(?:password|passwd|pwd|api_key|secret_key|token|credential|ssn|customer_ssn|password_attempt)[:=][\\'\"]?[^\\'\"\\s]+[\\'\"]?\\b')\n",
        "    ]\n",
        "\n",
        "    def _redact_value(self, value, key_context=None):\n",
        "        # If the current item is the value of a sensitive key, redact it directly\n",
        "        if isinstance(key_context, str) and key_context.lower() in self.SENSITIVE_KEYS:\n",
        "            return '********'\n",
        "\n",
        "        if isinstance(value, str):\n",
        "            redacted_value = value\n",
        "            for pattern in self.REDACTION_PATTERNS:\n",
        "                redacted_value = pattern.sub('********', redacted_value)\n",
        "            return redacted_value\n",
        "        elif isinstance(value, dict):\n",
        "            # Recursively redact values in a dictionary, passing the key as context\n",
        "            return {k: self._redact_value(v, k) for k, v in value.items()}\n",
        "        elif isinstance(value, list):\n",
        "            # Recursively redact elements in a list (no key_context for list items themselves)\n",
        "            return [self._redact_value(item, None) for item in value]\n",
        "        else:\n",
        "            return value\n",
        "\n",
        "    def format(self, record):\n",
        "        # Create a dictionary from the log record attributes\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.datetime.fromtimestamp(record.created).isoformat(),\n",
        "            \"level\": record.levelname,\n",
        "            \"message\": self._redact_value(record.getMessage()), # Redact the main message\n",
        "            \"logger_name\": record.name,\n",
        "            \"filename\": record.filename,\n",
        "            \"lineno\": record.lineno,\n",
        "            \"process\": record.process,\n",
        "            \"thread\": record.thread,\n",
        "            \"funcName\": getattr(record, 'funcName', None),\n",
        "            \"taskName\": getattr(record, 'taskName', None) # Read taskName if it exists\n",
        "        }\n",
        "\n",
        "        # Define a set of standard LogRecord attributes to avoid duplication\n",
        "        STANDARD_LOG_RECORD_ATTRIBUTES = {\n",
        "            'name', 'levelname', 'levelno', 'pathname', 'filename', 'module', 'lineno',\n",
        "            'funcName', 'created', 'asctime', 'msecs', 'relativeCreated', 'thread',\n",
        "            'threadName', 'process', 'processName', 'message', 'args', 'exc_info',\n",
        "            'exc_text', 'stack_info', 'msg',\n",
        "            'extra' # if the 'extra' dict itself is somehow present as an attribute\n",
        "        }\n",
        "\n",
        "        # Add extra attributes from the log record and recursively redact them, passing the key as context\n",
        "        for key, value in record.__dict__.items():\n",
        "            if not key.startswith('_') and key not in log_entry and key not in STANDARD_LOG_RECORD_ATTRIBUTES:\n",
        "                log_entry[key] = self._redact_value(value, key)\n",
        "\n",
        "        # Serialize the dictionary to a JSON string\n",
        "        return json.dumps(log_entry, default=str)\n",
        "\n",
        "\n",
        "# Configure a new logger with the StructuredJsonFormatter and TimedRotatingFileHandler\n",
        "# Reset existing handlers to avoid duplicates if cell is re-run\n",
        "root_logger = logging.getLogger()\n",
        "for handler in root_logger.handlers[:]:\n",
        "    root_logger.removeHandler(handler)\n",
        "\n",
        "root_logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create handlers\n",
        "# 1. Console Handler (StreamHandler)\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "# 2. Timed Rotating File Handler for log retention\n",
        "# Rotates every minute, keeps 5 backup files (for demonstration purposes)\n",
        "# In a real application, 'when' could be 'midnight' or 'H' (hourly) with larger intervals.\n",
        "file_handler = TimedRotatingFileHandler(log_file, when='M', interval=1, backupCount=5)\n",
        "\n",
        "# Create a structured JSON formatter instance\n",
        "json_formatter = StructuredJsonFormatter()\n",
        "\n",
        "# Set formatter for handlers\n",
        "file_handler.setFormatter(json_formatter)\n",
        "stream_handler.setFormatter(json_formatter)\n",
        "\n",
        "# Add handlers to the logger\n",
        "root_logger.addHandler(file_handler)\n",
        "root_logger.addHandler(stream_handler)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\n--- Demonstrating Structured JSON Logging with Recursive Redaction and Log Rotation ---\")\n",
        "print(f\"Logs will be written to '{log_file}' and rotated (keeping 5 backups) every minute.\")\n",
        "\n",
        "# Example logs with structured data, including nested sensitive data\n",
        "logger.info(\"User activity\", extra={\"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"})\n",
        "logger.warning(\"Configuration error\", extra={\"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3})\n",
        "\n",
        "# Example with sensitive data in message and extra fields, to test redaction within structured logs\n",
        "logger.critical(\n",
        "    \"Security alert: User login failed. password_attempt=weakpass123\",\n",
        "    extra={\n",
        "        \"user_email\": \"attacker@example.com\",\n",
        "        \"ip_address\": \"192.0.2.10\",\n",
        "        \"auth_details\": {\n",
        "            \"username\": \"badactor\",\n",
        "            \"password\": \"anotherbadpassword\",\n",
        "            \"api_key\": \"nested_secret_key_123\"\n",
        "        },\n",
        "        \"attempts\": [\n",
        "            {\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"oldpass@domain.com\"},\n",
        "            {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"badpassword\"}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "logger.info(\"New registration\", extra={\"username\": \"new_user\", \"email\": \"newuser@example.org\", \"registration_ip\": \"10.0.0.5\"})\n",
        "logger.info(\"Payment initiated\", extra={\"transaction_id\": \"TXN789\", \"customer_ssn\": \"987-65-4321\", \"amount\": 199.99})\n",
        "\n",
        "print(f\"Structured JSON logging with recursive redaction and rotation configured. Check '{log_file}' and console for logs.\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"timestamp\": \"2026-01-29T08:57:42.868354\", \"level\": \"INFO\", \"message\": \"User activity\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-986578396.py\", \"lineno\": 117, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_id\": \"U007\", \"event\": \"view_product\", \"product_id\": \"P012\"}\n",
            "{\"timestamp\": \"2026-01-29T08:57:42.872738\", \"level\": \"WARNING\", \"message\": \"Configuration error\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-986578396.py\", \"lineno\": 118, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"component\": \"database\", \"issue\": \"connection_timeout\", \"retry_count\": 3}\n",
            "{\"timestamp\": \"2026-01-29T08:57:42.876206\", \"level\": \"CRITICAL\", \"message\": \"Security alert: User login failed. ********\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-986578396.py\", \"lineno\": 121, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"user_email\": \"********\", \"ip_address\": \"192.0.2.10\", \"auth_details\": {\"username\": \"badactor\", \"password\": \"********\", \"api_key\": \"********\"}, \"attempts\": [{\"timestamp\": \"2023-01-01T10:00:00\", \"credential\": \"********\"}, {\"timestamp\": \"2023-01-01T10:01:00\", \"credential\": \"********\"}]}\n",
            "{\"timestamp\": \"2026-01-29T08:57:42.880056\", \"level\": \"INFO\", \"message\": \"New registration\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-986578396.py\", \"lineno\": 137, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"username\": \"new_user\", \"email\": \"********\", \"registration_ip\": \"10.0.0.5\"}\n",
            "{\"timestamp\": \"2026-01-29T08:57:42.896221\", \"level\": \"INFO\", \"message\": \"Payment initiated\", \"logger_name\": \"__main__\", \"filename\": \"ipython-input-986578396.py\", \"lineno\": 138, \"process\": 475, \"thread\": 139147254714368, \"funcName\": \"<cell line: 0>\", \"taskName\": \"Task-3\", \"transaction_id\": \"TXN789\", \"customer_ssn\": \"********\", \"amount\": 199.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Structured JSON Logging with Recursive Redaction and Log Rotation ---\n",
            "Logs will be written to 'app.log' and rotated (keeping 5 backups) every minute.\n",
            "Structured JSON logging with recursive redaction and rotation configured. Check 'app.log' and console for logs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UwgU9wP4C9sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5"
      ],
      "metadata": {
        "id": "ITygO-1h_OhW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "880a1595",
        "outputId": "c756b6a3-241b-4f7a-d82d-1bee21806d16"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 1. Generate a synthetic dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, random_state=42)\n",
        "print(\"Dataset generated: Features (X) shape:\", X.shape, \", Target (y) shape:\", y.shape)\n",
        "\n",
        "# 2. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"\\nData split into training and testing sets:\")\n",
        "print(\"  X_train shape:\", X_train.shape)\n",
        "print(\"  X_test shape:\", X_test.shape)\n",
        "print(\"  y_train shape:\", y_train.shape)\n",
        "print(\"  y_test shape:\", y_test.shape)\n",
        "\n",
        "# 3. Instantiate a Linear Regression model\n",
        "model = LinearRegression()\n",
        "print(\"\\nLinear Regression model instantiated.\")\n",
        "\n",
        "# 4. Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model trained successfully on the training data.\")\n",
        "\n",
        "# 5. Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\nPredictions made on the test set.\")\n",
        "\n",
        "# 6. Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"  R-squared (R2) Score: {r2:.2f}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generated: Features (X) shape: (1000, 10) , Target (y) shape: (1000,)\n",
            "\n",
            "Data split into training and testing sets:\n",
            "  X_train shape: (800, 10)\n",
            "  X_test shape: (200, 10)\n",
            "  y_train shape: (800,)\n",
            "  y_test shape: (200,)\n",
            "\n",
            "Linear Regression model instantiated.\n",
            "Model trained successfully on the training data.\n",
            "\n",
            "Predictions made on the test set.\n",
            "\n",
            "Model Evaluation:\n",
            "  Mean Squared Error (MSE): 0.00\n",
            "  R-squared (R2) Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "28515d66",
        "outputId": "64096fa3-6895-4e11-8cd1-88ad86750eee"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\"\"\"\n",
        "Purpose: This code demonstrates a basic machine learning workflow using a simple linear regression model.\n",
        "It generates a synthetic dataset, splits it into training and testing sets, trains a Linear Regression model,\n",
        "makes predictions, and evaluates the model's performance using Mean Squared Error (MSE) and R-squared (R2).\n",
        "\n",
        "Responsible Use Considerations:\n",
        "\n",
        "Model Explainability:\n",
        "  Linear Regression models are generally considered highly interpretable. The coefficients learned by the model\n",
        "  directly indicate the strength and direction of the relationship between each input feature and the target variable.\n",
        "  For example, a positive coefficient means an increase in that feature leads to an increase in the target.\n",
        "  For more complex, 'black-box' models (e.g., deep neural networks), additional explainability techniques like LIME,\n",
        "  SHAP, or Partial Dependence Plots would be necessary to understand their decisions.\n",
        "\n",
        "Accuracy Limitations:\n",
        "  While this demonstration uses a synthetic dataset that often results in near-perfect accuracy (e.g., MSE close to 0, R2 close to 1),\n",
        "  real-world data is inherently noisy, complex, and often incomplete. Therefore, actual model performance in production\n",
        "  would vary significantly. It is crucial to perform careful validation on diverse, real-world data and understand that\n",
        "  model accuracy is not an absolute measure but context-dependent.\n",
        "\n",
        "Potential Biases:\n",
        "  This synthetic dataset is designed to be unbiased. However, in real-world applications, training data can contain inherent biases.\n",
        "  These biases might stem from historical inequalities, under-representation of certain demographic groups, or flaws in data collection.\n",
        "  If present, such biases can lead to unfair, discriminatory, or inequitable outcomes when the model is applied.\n",
        "  It is essential to proactively detect and mitigate biases in data and model predictions using techniques like fairness metrics,\n",
        "  bias detection tools, and re-sampling methods.\n",
        "\n",
        "Deployment and Monitoring Guidance:\n",
        "  Before deploying any machine learning model into a production environment, rigorous testing is paramount.\n",
        "  This includes performance testing, robustness checks, and fairness assessments. Post-deployment, continuous monitoring\n",
        "  is absolutely necessary. This monitoring should track:\n",
        "  - Model performance over time (e.g., accuracy, precision, recall, F1-score).\n",
        "  - Data drift (changes in input data distributions).\n",
        "  - Concept drift (changes in the relationship between input and output variables).\n",
        "  - Fairness metrics to ensure the model does not develop or exacerbate biases.\n",
        "  - Anomaly detection for unexpected model behavior. Regular retraining with fresh, representative data may also be required.\n",
        "\"\"\"\n",
        "\n",
        "# 1. Generate a synthetic dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, random_state=42)\n",
        "print(\"Dataset generated: Features (X) shape:\", X.shape, \", Target (y) shape:\", y.shape)\n",
        "\n",
        "# 2. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"\\nData split into training and testing sets:\")\n",
        "print(\"  X_train shape:\", X_train.shape)\n",
        "print(\"  X_test shape:\", X_test.shape)\n",
        "print(\"  y_train shape:\", y_train.shape)\n",
        "print(\"  y_test shape:\", y_test.shape)\n",
        "\n",
        "# 3. Instantiate a Linear Regression model\n",
        "model = LinearRegression()\n",
        "print(\"\\nLinear Regression model instantiated.\")\n",
        "\n",
        "# 4. Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model trained successfully on the training data.\")\n",
        "\n",
        "# 5. Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\nPredictions made on the test set.\")\n",
        "\n",
        "# 6. Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"  R-squared (R2) Score: {r2:.2f}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generated: Features (X) shape: (1000, 10) , Target (y) shape: (1000,)\n",
            "\n",
            "Data split into training and testing sets:\n",
            "  X_train shape: (800, 10)\n",
            "  X_test shape: (200, 10)\n",
            "  y_train shape: (800,)\n",
            "  y_test shape: (200,)\n",
            "\n",
            "Linear Regression model instantiated.\n",
            "Model trained successfully on the training data.\n",
            "\n",
            "Predictions made on the test set.\n",
            "\n",
            "Model Evaluation:\n",
            "  Mean Squared Error (MSE): 0.00\n",
            "  R-squared (R2) Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUMMARY**\n",
        "\n",
        "GitHub Copilot was used to generate a basic machine learning model in Python. A follow-up prompt added documentation describing responsible usage, including explainability, accuracy limitations, and bias awareness. This approach promotes ethical and transparent use of machine learning systems."
      ],
      "metadata": {
        "id": "kk2fewcvDKI1"
      }
    }
  ]
}